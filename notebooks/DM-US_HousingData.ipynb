{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project\n",
    "### By:  Group 3: Elio Aybar, Cristal Garcia, Sunny Li, Matt Norgren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to import\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "pd.set_option('display.max_columns', 100) # Setting pandas to display a N number of columns\n",
    "pd.set_option('display.max_rows', 10) # Setting pandas to display a N number rows\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,VotingClassifier,BaggingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from hypopt import GridSearch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron,SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAN\\OneDrive - The University of Chicago\\2020_Autumn\\Data Mining Platforms [MSCA 31008]\\Group_Project\n"
     ]
    }
   ],
   "source": [
    "### IMPORT SET\n",
    "\n",
    "#Change working directory to match where the large files are stored\n",
    "# it is not best practice to centrally store files this large - although\n",
    "# git LFS should be explored\n",
    "\n",
    "### CWD -  MAN\n",
    "%cd \"C:\\Users\\MAN\\OneDrive - The University of Chicago\\2020_Autumn\\Data Mining Platforms [MSCA 31008]\\Group_Project\\\"\n",
    "## CWD - Cristal\n",
    "#%cd \"C:\\Users\\cgarc\\OneDrive - The University of Chicago\\GitHub\\US_HousingData-\\docs\"\n",
    "#cd\n",
    "## CWD - Elio \n",
    "#%cd \"C:\\Users\\Tipo\\Desktop\\GitHub\\Project\"\n",
    "## CWD - Sunny\n",
    "#%cd \"/Users/sunny/Data mining/final project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Establish Pandas Data Frames / Import\n",
    "\n",
    "### Zillow Set- Zip \n",
    "zip_df = pd.read_csv('Zip_time_series.csv', index_col = 'Date')  ### Issues with NaN on import\n",
    "\n",
    "## Public School Ratings \n",
    "PS_df = pd.read_csv('Public_Schools.csv')\n",
    "\n",
    "## Starbucks Upto 2017 for 70 Countries\n",
    "SBUX_df = pd.read_csv('directory.csv')\n",
    "\n",
    "## Food Desert \n",
    "foodlookup_df = pd.read_csv('food_access_variable_lookup.csv')\n",
    "food_df = pd.read_csv('food_access_research_atlas.csv') \n",
    "\n",
    "## Hospital Quality Care \n",
    "hospital_df = pd.read_csv('Hospital General Information.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "## Target Up to 2017 for US \n",
    "TGT_df = pd.read_csv('target.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Set Cleaning (Preparing for Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72864, 147)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "## Food Desert -- Cleaning CG  #\n",
    "################################\n",
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to drop\n",
    "food_df.drop(['GroupQuartersFlag', 'NUMGQTRS', 'PCTGQTRS', 'LILATracts_Vehicle',  'LATractsVehicle_20', 'LAPOP1_10', 'LAPOP05_10', 'LAPOP1_20', 'LALOWI1_10', 'LALOWI05_10', 'LALOWI1_20', 'lapophalf', 'lapophalfshare', 'lalowihalf', 'lalowihalfshare', 'lakidshalf', 'lakidshalfshare', 'laseniorshalf', 'laseniorshalfshare', 'lawhitehalf', 'lawhitehalfshare', 'lablackhalf', 'lablackhalfshare', 'laasianhalf', 'laasianhalfshare'], axis = 1, inplace = True)\n",
    "food_df.drop(['lanhopihalf', 'lanhopihalfshare', 'laaianhalf', 'laaianhalfshare', 'laomultirhalf', 'laomultirhalfshare', 'lahisphalf', 'lahisphalfshare', 'lahunvhalf', 'lahunvhalfshare', 'lasnaphalf', 'lasnaphalfshare', 'lapop1', 'lapop1share', 'lalowi1', 'lalowi1share', 'lakids1', 'lakids1share', 'laseniors1', 'laseniors1share', 'lawhite1', 'lawhite1share', 'lablack1', 'lablack1share', 'laasian1', 'laasian1share', 'lanhopi1', 'lanhopi1share', 'laaian1', 'laaian1share', 'laomultir1', 'laomultir1share', 'lahisp1', 'lahisp1share', 'lahunv1', 'lahunv1share'], axis = 1, inplace = True)\n",
    "food_df.drop(['lasnap1', 'lasnap1share', 'lapop10', 'lapop10share', 'lalowi10', 'lalowi10share', 'lakids10', 'lakids10share', 'laseniors10', 'laseniors10share', 'lawhite10', 'lawhite10share', 'lablack10', 'lablack10share', 'laasian10', 'laasian10share', 'lanhopi10', 'lanhopi10share', 'laaian10', 'laaian10share', 'laomultir10', 'laomultir10share', 'lahisp10', 'lahisp10share', 'lahunv10', 'lahunv10share', 'lasnap10', 'lasnap10share', 'lapop20', 'lapop20share', 'lalowi20', 'lalowi20share', 'lakids20', 'lakids20share', 'laseniors20', 'laseniors20share'], axis = 1, inplace = True)\n",
    "food_df.drop(['lawhite20', 'lawhite20share', 'lablack20', 'lablack20share', 'laasian20', 'laasian20share', 'lanhopi20', 'lanhopi20share', 'laaian20', 'laaian20share', 'laomultir20', 'laomultir20share', 'lahisp20', 'lahisp20share', 'lahunv20', 'lahunv20share'], axis = 1, inplace = True)\n",
    "food_df.drop(['LILATracts_1And10', 'LILATracts_halfAnd10', 'LILATracts_1And20', 'HUNVFlag', 'lasnap20', 'lasnap20share', 'TractLOWI', 'TractKids', 'TractSeniors', 'TractWhite', 'TractBlack', 'TractAsian', 'TractNHOPI', 'TractAIAN', 'TractOMultir', 'TractHispanic', 'TractHUNV', 'TractSNAP'], axis = 1, inplace = True)\n",
    "food_df.drop(['LAhalfand10', 'LA1and20', 'LATracts_half', 'LATracts1', 'LATracts10', 'LATracts20'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplication rows\n",
    "food_df.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Zipcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Zipcode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b3096d6c7ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#couldn't be identified and were replaced with NA's. Drop these respective rows with NA's in zipcode because those aren't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#functional censustract numbers and the rows also have 0's for more than 70% of columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfood_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfood_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfood_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Zipcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Zipcode'"
     ]
    }
   ],
   "source": [
    "#There are rows in the data with censustract numbers that no longer apply and the respective row has zero values. Zipcodes \n",
    "#couldn't be identified and were replaced with NA's. Drop these respective rows with NA's in zipcode because those aren't \n",
    "#functional censustract numbers and the rows also have 0's for more than 70% of columns\n",
    "food_df = food_df[food_df['Zipcode'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values\n",
    "food_df.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique values\n",
    "food_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Visually represent collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(food_df.corr(),annot=True,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Zipcode and find the average of features\n",
    "food_df = food_df.groupby('Zipcode', as_index=False)['Urban', 'POP2010', 'OHU2010', 'LowIncomeTracts', 'PovertyRate', 'MedianFamilyIncome', 'LA1and10'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "## Public School Ratings (2014-2015 School years) -- Cleaning CG  ##\n",
    "####################################################################\n",
    "\n",
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'LEVEL_' to change to integer (1: elementary, 2: middle school, 3: high school, 4:PK-13, N=0: Not specified)\n",
    "PS_df['LEVEL_'] = PS_df['LEVEL_'].apply({'N':0, '1':1, '2':2, '3':3, '4':4 }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ZIP4 because 43% of data missing and already have other location indicators; don't need Telephone, website, source, \n",
    "#'VAL_METHOD', 'NAICS_CODE'; 'NAICS_DESC' is generalized description of 'LEVEL'; SHELTER_ID doesn't have 76% of data available \n",
    "\n",
    "PS_df.drop(['X', 'Y', 'OBJECTID', 'NCESID', 'ZIP4', 'TELEPHONE', 'NAICS_CODE', 'NAICS_DESC', 'SOURCE', 'VAL_METHOD', 'VAL_DATE',  'WEBSITE', 'ST_GRADE', 'END_GRADE', 'DISTRICTID',  'SHELTER_ID'], axis = 1, inplace = True)\n",
    "\n",
    "#Drop Puerto Rico location\n",
    "PS_df = PS_df[PS_df.COUNTRY != 'PRI']\n",
    "\n",
    "#Drop Country column since all inland\n",
    "PS_df.drop(['COUNTRY'], axis = 1, inplace = True)\n",
    "\n",
    "#Convert SOURCEDATE to actual datatime type\n",
    "PS_df['SOURCEDATE'] = pd.to_datetime(PS_df['SOURCEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplication rows\n",
    "PS_df.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop schools with 0 and negative enrolment\n",
    "PS_df = PS_df[PS_df.ENROLLMENT > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop schools with 0 and negative count of teachers\n",
    "PS_df = PS_df[PS_df.FT_TEACHER > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Student: Teacher ratio based on enrollment and Teacher count. 30:1 is the ideal ratio \n",
    "PS_df['Class_Teacher_RATIO'] = PS_df['ENROLLMENT'] / PS_df['FT_TEACHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Visually represent collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(PS_df.corr(),annot=True,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Population, Enrollment, and FT_Teacher columns since they have collinearity and enrollment and FT_teacher included in \n",
    "#Class_Teacher_RATIO\n",
    "PS_df.drop(['POPULATION', 'ENROLLMENT', 'FT_TEACHER'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Zipcode and find avg of features per zipcode\n",
    "PS_df = PS_df.groupby('ZIP', as_index=False)['TYPE', 'STATUS', 'LEVEL_', 'Class_Teacher_RATIO'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Target -- Cleaning EA #\n",
    "##########################\n",
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select desired variables\n",
    "TGT_df = TGT_df[['Address.FormattedAddress','Address.AddressLine1','Address.City','Address.CountryName','Address.Latitude','Address.Longitude','Address.County','Address.PostalCode','Address.Subdivision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analize variable information\n",
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(TGT_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change variable names\n",
    "TGT_df = TGT_df.rename(columns={\"Address.FormattedAddress\": \"FormattedAddress\", \n",
    "                   \"Address.AddressLine1\": \"AddressLine1\",\n",
    "                   \"Address.City\": \"City\",\n",
    "                   \"Address.CountryName\": \"CountryName\",\n",
    "                   \"Address.Latitude\": \"Latitude\",\n",
    "                   \"Address.Longitude\": \"Longitude\",\n",
    "                   \"Address.County\": \"County\",\n",
    "                   \"Address.PostalCode\": \"PostalCode\",\n",
    "                   \"Address.Subdivision\": \"Subdivision\",\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values in column County variable\n",
    "TGT_df = TGT_df[TGT_df.County.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(TGT_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column that identifies Target at specified address (will groupby zipcode and count the number of targets by zipcode)\n",
    "TGT_df['Target_count'] = 1\n",
    "TGT_df = TGT_df.groupby('PostalCode', as_index=False)['Target_count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull shortened zipcode for Target data\n",
    "TGT_df['PostalCode'] = [x[:5] for x in TGT_df['PostalCode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert values to integers\n",
    "TGT_df['PostalCode'] = TGT_df.PostalCode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Starbucks -- Cleaning EA #\n",
    "#############################\n",
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1 = SBUX_df['Brand']\n",
    "print(A_1.groupby(A_1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_2 = SBUX_df['Country']\n",
    "print(A_2.groupby(A_2).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df[SBUX_df[\"Brand\"] == 'Starbucks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df[SBUX_df[\"Country\"] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select desired variables\n",
    "SBUX_df = SBUX_df[['Brand','Street Address','City','State/Province','Country','Postcode','Longitude','Latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(SBUX_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values in column County variable\n",
    "SBUX_df = SBUX_df[SBUX_df.Postcode .notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(SBUX_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column that identifies Starbucks at specified address (will groupby zipcode and count the number of targets by zipcode)\n",
    "SBUX_df['Starbucks_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SBUX_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull shortened zipcode for Starbucks data\n",
    "SBUX_df['Postcode'] = [x[:5] for x in SBUX_df['Postcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df.groupby('Postcode', as_index=False)['Starbucks_count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert values to integers\n",
    "SBUX_df['Postcode']= SBUX_df.Postcode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Zip -- Cleaning MN #\n",
    "#######################\n",
    "zip_df.shape\n",
    "#Understand range of outputs\n",
    "#zip_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understand the number of nulls\n",
    "zip_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish two new columns in order to test logic of replacement / consolidation\n",
    "zip_df['NumberOfBedrooms'] = 0\n",
    "zip_df['DwellingType'] = 0\n",
    "zip_df['MedianListingPricePerSqft'] = 0\n",
    "zip_df['MedianListingPrice'] = 0\n",
    "zip_df['MedianRentalPrice'] = 0\n",
    "zip_df['MedianRentalPricePerSqft'] = 0\n",
    "zip_df['MedianListPPS_D'] = 0\n",
    "zip_df['MedianList_D'] = 0\n",
    "zip_df['MedianRentalPPS_D'] = 0\n",
    "zip_df['MedianRental_D'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace null with 0\n",
    "zip_df['MedianListingPricePerSqft_1Bedroom'] = zip_df['MedianListingPricePerSqft_1Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_2Bedroom'] = zip_df['MedianListingPricePerSqft_2Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_3Bedroom'] = zip_df['MedianListingPricePerSqft_3Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_4Bedroom'] = zip_df['MedianListingPricePerSqft_4Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_5BedroomOrMore'] = zip_df['MedianListingPricePerSqft_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_1Bedroom'] = zip_df['MedianListingPrice_1Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_2Bedroom'] = zip_df['MedianListingPrice_2Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_3Bedroom'] = zip_df['MedianListingPrice_3Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_4Bedroom'] = zip_df['MedianListingPrice_4Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_5BedroomOrMore'] = zip_df['MedianListingPrice_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPricePerSqft_1Bedroom'] = zip_df['MedianRentalPricePerSqft_1Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_2Bedroom'] = zip_df['MedianRentalPricePerSqft_2Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_3Bedroom'] = zip_df['MedianRentalPricePerSqft_3Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_4Bedroom'] = zip_df['MedianRentalPricePerSqft_4Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_5BedroomOrMore'] = zip_df['MedianRentalPricePerSqft_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPrice_1Bedroom'] = zip_df['MedianRentalPrice_1Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_2Bedroom'] = zip_df['MedianRentalPrice_2Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_3Bedroom'] = zip_df['MedianRentalPrice_3Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_4Bedroom'] = zip_df['MedianRentalPrice_4Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_5BedroomOrMore'] = zip_df['MedianRentalPrice_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_AllHomes'] = zip_df['MedianListingPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPrice_CondoCoop'] = zip_df['MedianListingPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPrice_DuplexTriplex'] = zip_df['MedianListingPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPrice_SingleFamilyResidence'] = zip_df['MedianListingPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_AllHomes'] = zip_df['MedianListingPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPrice_CondoCoop'] = zip_df['MedianListingPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPrice_DuplexTriplex'] = zip_df['MedianListingPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPrice_SingleFamilyResidence'] = zip_df['MedianListingPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPricePerSqft_AllHomes'] = zip_df['MedianListingPricePerSqft_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_CondoCoop'] = zip_df['MedianListingPricePerSqft_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_DuplexTriplex'] = zip_df['MedianListingPricePerSqft_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_SingleFamilyResidence'] = zip_df['MedianListingPricePerSqft_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPrice_AllHomes'] = zip_df['MedianRentalPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianRentalPrice_CondoCoop'] = zip_df['MedianRentalPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianRentalPrice_DuplexTriplex'] = zip_df['MedianRentalPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianRentalPrice_SingleFamilyResidence'] = zip_df['MedianRentalPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPricePerSqft_AllHomes'] = zip_df['MedianRentalPricePerSqft_AllHomes'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_CondoCoop'] = zip_df['MedianRentalPricePerSqft_CondoCoop'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_DuplexTriplex'] = zip_df['MedianRentalPricePerSqft_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'] = zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_AllHomes'] = zip_df['MedianPctOfPriceReduction_AllHomes'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_CondoCoop'] = zip_df['MedianPctOfPriceReduction_CondoCoop'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_SingleFamilyResidence'] = zip_df['MedianPctOfPriceReduction_SingleFamilyResidence'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_AllHomes'] = zip_df['MedianPriceCutDollar_AllHomes'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_CondoCoop'] = zip_df['MedianPriceCutDollar_CondoCoop'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_SingleFamilyResidence'] = zip_df['MedianPriceCutDollar_SingleFamilyResidence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized set in order to iterate through and assign a value to the new column created\n",
    "## Many prior attempts utilized a more if then style structure but inevitably took a considerably long time\n",
    "## and replaced when the value was 0  thus overwriting the prior data at every run\n",
    "##WC: https://guillim.github.io/pandas/2018/10/22/Pandas-if-else-on-columns.html \n",
    "\n",
    "condlist = [\n",
    "    (zip_df['MedianListingPricePerSqft_1Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_2Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_3Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_4Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_5BedroomOrMore'] != 0)\n",
    "]\n",
    "\n",
    "condlist2 = [(zip_df['MedianRentalPricePerSqft_AllHomes'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_CondoCoop'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_DuplexTriplex'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_Studio'] != 0)\n",
    "]\n",
    "      \n",
    "#Establish if the criteria is met - what is the result\n",
    "choicelist = [1,2,3,4,5]\n",
    "choicelist2 = ['All','Condo','Duplex+','Single','Multi5+','Studio']\n",
    "#Overwrite the number of bedroom columns with the given logic output \n",
    "zip_df['NumberOfBedrooms'] = np.select(condlist,choicelist)\n",
    "zip_df['DwellingType'] = np.select(condlist2,choicelist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumberOfBedrooms\n",
       "0    3951999\n",
       "1       8194\n",
       "2      80569\n",
       "3     310476\n",
       "4      30627\n",
       "5       2020\n",
       "Name: NumberOfBedrooms, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count per of decided bedrooms\n",
    "zip_df['NumberOfBedrooms'].groupby(zip_df['NumberOfBedrooms']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DwellingType\n",
       "All         120843\n",
       "Condo          677\n",
       "Duplex+       1231\n",
       "Multi5+    4260210\n",
       "Single         924\n",
       "Name: DwellingType, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count per of decided dwelling types\n",
    "zip_df['DwellingType'].groupby(zip_df['DwellingType']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Further Cleanup of like variables\n",
    "\n",
    "## Optimized set in order to iterate through and assign a value to the new column created\n",
    "## Many prior attempts utilized a more if then style structure but inevitably took a considerably long time\n",
    "## and replaced when the value was 0  thus overwriting the prior data at every run\n",
    "##WC: https://guillim.github.io/pandas/2018/10/22/Pandas-if-else-on-columns.html \n",
    "\n",
    "#condlist2 = [\n",
    "#    (zip_df['MedianListingPrice_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_5BedroomOrMore'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_5BedroomOrMore'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_5BedroomOrMore'] != 0)\n",
    "#]\n",
    "#Establish if the criteria is met - what is the result\n",
    "#choicelist2 = [1,1,1,2,2,2,3,3,3,4,4,4,5,5,5]\n",
    "#Overwrite the number of bedroom columns with the given logic output \n",
    "#zip_df['NumberOfBedrooms'] = np.select(condlist2,choicelist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combine the bedroom columns into the median listing price per sqft column to reduce column space\n",
    "\n",
    "zip_df['MedianListingPricePerSqft'] = (zip_df['MedianListingPricePerSqft_1Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_2Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_3Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_4Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_5BedroomOrMore'])\n",
    "zip_df['MedianListingPrice'] = (zip_df['MedianListingPrice_1Bedroom']\n",
    "          + zip_df['MedianListingPrice_2Bedroom']\n",
    "          + zip_df['MedianListingPrice_3Bedroom']\n",
    "          + zip_df['MedianListingPrice_4Bedroom']\n",
    "          + zip_df['MedianListingPrice_5BedroomOrMore'])\n",
    "zip_df['MedianRentalPricePerSqft'] = (zip_df['MedianRentalPricePerSqft_1Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_2Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_3Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_4Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_5BedroomOrMore'])\n",
    "zip_df['MedianRentalPrice'] = (zip_df['MedianRentalPrice_1Bedroom']\n",
    "          + zip_df['MedianRentalPrice_2Bedroom']\n",
    "          + zip_df['MedianRentalPrice_3Bedroom']\n",
    "          + zip_df['MedianRentalPrice_4Bedroom']\n",
    "          + zip_df['MedianRentalPrice_5BedroomOrMore'])\n",
    "zip_df['MedianListPPS_D'] = (zip_df['MedianListingPricePerSqft_AllHomes']\n",
    "          + zip_df['MedianListingPricePerSqft_CondoCoop']\n",
    "          + zip_df['MedianListingPricePerSqft_DuplexTriplex']\n",
    "          + zip_df['MedianListingPricePerSqft_SingleFamilyResidence'])\n",
    "zip_df['MedianList_D'] = (zip_df['MedianListingPrice_AllHomes']\n",
    "          + zip_df['MedianListingPrice_CondoCoop']\n",
    "          + zip_df['MedianListingPrice_DuplexTriplex']\n",
    "          + zip_df['MedianListingPrice_SingleFamilyResidence'])\n",
    "zip_df['MedianRentalPPS_D'] = (zip_df['MedianRentalPricePerSqft_AllHomes']\n",
    "          + zip_df['MedianRentalPricePerSqft_CondoCoop']\n",
    "          + zip_df['MedianRentalPricePerSqft_DuplexTriplex']\n",
    "          + zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'])\n",
    "zip_df['MedianRental_D'] = (zip_df['MedianRentalPrice_AllHomes']\n",
    "          + zip_df['MedianRentalPrice_CondoCoop']\n",
    "          + zip_df['MedianRentalPrice_DuplexTriplex']\n",
    "          + zip_df['MedianRentalPrice_SingleFamilyResidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop unneeded columns\n",
    "zip_df = zip_df[[\n",
    "         'RegionName'\n",
    "        , 'NumberOfBedrooms'\n",
    "        , 'DwellingType'\n",
    "        , 'MedianListingPricePerSqft'\n",
    "        , 'MedianListingPrice'\n",
    "        , 'MedianRentalPrice'\n",
    "        , 'MedianRentalPricePerSqft'\n",
    "        , 'MedianListPPS_D'\n",
    "        , 'MedianList_D'\n",
    "        , 'MedianRentalPPS_D'\n",
    "        , 'MedianRental_D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish date range to 2017 for normalization\n",
    "zip_df = zip_df.loc['2017-01-01':'2017-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zip_df.groupby('RegionName')['MedianListingPricePerSqft'\n",
    "                               ,'MedianListingPrice'\n",
    "                              , 'MedianRentalPrice'\n",
    "                              , 'MedianRentalPricePerSqft'\n",
    "                              , 'MedianListPPS_D'\n",
    "                              , 'MedianList_D'\n",
    "                              , 'MedianRentalPPS_D'\n",
    "                              , 'MedianRental_D'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedianListingPricePerSqft</th>\n",
       "      <th>MedianListingPrice</th>\n",
       "      <th>MedianRentalPrice</th>\n",
       "      <th>MedianRentalPricePerSqft</th>\n",
       "      <th>MedianListPPS_D</th>\n",
       "      <th>MedianList_D</th>\n",
       "      <th>MedianRentalPPS_D</th>\n",
       "      <th>MedianRental_D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.251936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>148.765226</td>\n",
       "      <td>188391.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.185273</td>\n",
       "      <td>432857.791667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.350790</td>\n",
       "      <td>780231.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>167.314507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.617181</td>\n",
       "      <td>630970.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.324182</td>\n",
       "      <td>425082.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>464950.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99801</th>\n",
       "      <td>225.625175</td>\n",
       "      <td>341558.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446.363431</td>\n",
       "      <td>737204.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99835</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>897925.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99901</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.052447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19047 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MedianListingPricePerSqft  MedianListingPrice  MedianRentalPrice  MedianRentalPricePerSqft  MedianListPPS_D   MedianList_D  MedianRentalPPS_D  MedianRental_D\n",
       "RegionName                                                                                                                                                               \n",
       "745                          0.000000            0.000000                0.0                       0.0        94.251936       0.000000                0.0             0.0\n",
       "1001                       148.765226       188391.666667                0.0                       0.0       321.185273  432857.791667                0.0             0.0\n",
       "1002                         0.000000            0.000000                0.0                       0.0       409.350790  780231.250000                0.0             0.0\n",
       "1005                         0.000000            0.000000                0.0                       0.0         0.000000       0.000000                0.0             0.0\n",
       "1007                       167.314507            0.000000                0.0                       0.0       316.617181  630970.833333                0.0             0.0\n",
       "...                               ...                 ...                ...                       ...              ...            ...                ...             ...\n",
       "99709                        0.000000            0.000000                0.0                       0.0       372.324182  425082.958333                0.0             0.0\n",
       "99712                        0.000000            0.000000                0.0                       0.0         0.000000  464950.000000                0.0             0.0\n",
       "99801                      225.625175       341558.333333                0.0                       0.0       446.363431  737204.166667                0.0             0.0\n",
       "99835                        0.000000            0.000000                0.0                       0.0         0.000000  897925.000000                0.0             0.0\n",
       "99901                        0.000000            0.000000                0.0                       0.0       359.052447       0.000000                0.0             0.0\n",
       "\n",
       "[19047 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipt = zip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>InventorySeasonallyAdjusted_AllHomes</th>\n",
       "      <th>InventoryRaw_AllHomes</th>\n",
       "      <th>NumberOfBedrooms</th>\n",
       "      <th>DwellingType</th>\n",
       "      <th>MedianListingPricePerSqft_x</th>\n",
       "      <th>MedianListingPrice_x</th>\n",
       "      <th>MedianRentalPrice_x</th>\n",
       "      <th>MedianRentalPricePerSqft_x</th>\n",
       "      <th>MedianListPPS_D_x</th>\n",
       "      <th>MedianList_D_x</th>\n",
       "      <th>MedianRentalPPS_D_x</th>\n",
       "      <th>MedianRental_D_x</th>\n",
       "      <th>MedianListingPricePerSqft_y</th>\n",
       "      <th>MedianListingPrice_y</th>\n",
       "      <th>MedianRentalPrice_y</th>\n",
       "      <th>MedianRentalPricePerSqft_y</th>\n",
       "      <th>MedianListPPS_D_y</th>\n",
       "      <th>MedianList_D_y</th>\n",
       "      <th>MedianRentalPPS_D_y</th>\n",
       "      <th>MedianRental_D_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.055503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.251936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>62.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>133.277778</td>\n",
       "      <td>187450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.877118</td>\n",
       "      <td>422400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.765226</td>\n",
       "      <td>188391.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.185273</td>\n",
       "      <td>432857.791667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415.143257</td>\n",
       "      <td>721350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.350790</td>\n",
       "      <td>780231.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>154.434827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.983624</td>\n",
       "      <td>604850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.314507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.617181</td>\n",
       "      <td>630970.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228559</th>\n",
       "      <td>99709</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.425887</td>\n",
       "      <td>391345.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.324182</td>\n",
       "      <td>425082.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228560</th>\n",
       "      <td>99712</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>404400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>464950.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228561</th>\n",
       "      <td>99801</td>\n",
       "      <td>80.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>228.168542</td>\n",
       "      <td>359000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>448.180217</td>\n",
       "      <td>731950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.625175</td>\n",
       "      <td>341558.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446.363431</td>\n",
       "      <td>737204.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228562</th>\n",
       "      <td>99835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>893650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>897925.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228563</th>\n",
       "      <td>99901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Multi5+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>376.460506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359.052447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228564 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionName  InventorySeasonallyAdjusted_AllHomes  InventoryRaw_AllHomes  NumberOfBedrooms DwellingType  MedianListingPricePerSqft_x  MedianListingPrice_x  MedianRentalPrice_x  MedianRentalPricePerSqft_x  MedianListPPS_D_x  MedianList_D_x  MedianRentalPPS_D_x  MedianRental_D_x  MedianListingPricePerSqft_y  MedianListingPrice_y  MedianRentalPrice_y  MedianRentalPricePerSqft_y  MedianListPPS_D_y  MedianList_D_y  MedianRentalPPS_D_y  MedianRental_D_y\n",
       "0              745                                   NaN                    NaN                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0         100.055503             0.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0          94.251936        0.000000                  0.0               0.0\n",
       "1             1001                                  62.0                   52.0                 2      Multi5+                   133.277778              187450.0                  0.0                         0.0         299.877118        422400.0                  0.0               0.0                   148.765226         188391.666667                  0.0                         0.0         321.185273   432857.791667                  0.0               0.0\n",
       "2             1002                                 100.0                   66.0                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0         415.143257        721350.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0         409.350790   780231.250000                  0.0               0.0\n",
       "3             1005                                  24.0                   16.0                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0           0.000000             0.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0           0.000000        0.000000                  0.0               0.0\n",
       "4             1007                                  90.0                   70.0                 3      Multi5+                   154.434827                   0.0                  0.0                         0.0         291.983624        604850.0                  0.0               0.0                   167.314507              0.000000                  0.0                         0.0         316.617181   630970.833333                  0.0               0.0\n",
       "...            ...                                   ...                    ...               ...          ...                          ...                   ...                  ...                         ...                ...             ...                  ...               ...                          ...                   ...                  ...                         ...                ...             ...                  ...               ...\n",
       "228559       99709                                  57.0                   34.0                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0         360.425887        391345.5                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0         372.324182   425082.958333                  0.0               0.0\n",
       "228560       99712                                  43.0                   30.0                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0           0.000000        404400.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0           0.000000   464950.000000                  0.0               0.0\n",
       "228561       99801                                  80.0                   74.0                 3      Multi5+                   228.168542              359000.0                  0.0                         0.0         448.180217        731950.0                  0.0               0.0                   225.625175         341558.333333                  0.0                         0.0         446.363431   737204.166667                  0.0               0.0\n",
       "228562       99835                                   NaN                    NaN                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0           0.000000        893650.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0           0.000000   897925.000000                  0.0               0.0\n",
       "228563       99901                                   NaN                    NaN                 0      Multi5+                     0.000000                   0.0                  0.0                         0.0         376.460506             0.0                  0.0               0.0                     0.000000              0.000000                  0.0                         0.0         359.052447        0.000000                  0.0               0.0\n",
       "\n",
       "[228564 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipt_df = pd.merge(zipt,a,how='left',on='RegionName')\n",
    "zipt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionName\n",
       "745      12\n",
       "1001     12\n",
       "1002     12\n",
       "1005     12\n",
       "1007     12\n",
       "         ..\n",
       "99709    12\n",
       "99712    12\n",
       "99801    12\n",
       "99835    12\n",
       "99901    12\n",
       "Name: RegionName, Length: 19047, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipt_df['RegionName'].groupby(zipt_df['RegionName']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Still need to factorize dwelling type\n",
    "## Also need to dig into why 5+ is showing so often -- error in logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Hospital Quality Care -- Cleaning SL #\n",
    "#########################################\n",
    "hospital_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_df = hospital_df.isnull().sum(axis = 0).sort_values().to_frame('missing_value')\n",
    "null_df[null_df['missing_value'] > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop provider id, hospital name, address, phone number since they are all irrelevant \n",
    "# also drop all footnote since they are all incorporate in the other columns.\n",
    "drop_these = ['Provider ID', 'Hospital Name', 'Phone Number']\n",
    "drop_these.extend([col for col in hospital_df if 'footnote' in col])\n",
    "hospital_df = hospital_df.drop(columns = drop_these)\n",
    "\n",
    "# hospital_df.loc[:,hospital_df.columns.str.endswith('footnote')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = hospital_df.isnull().sum(axis = 0).sort_values().to_frame('missing_value')\n",
    "null_df[null_df['missing_value'] > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hospital_df['Meets criteria for meaningful use of EHRs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Meets criteria for meaningful use of EHRs'] = hospital_df['Meets criteria for meaningful use of EHRs'].fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['County Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Hospital Ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Hospital Ownership'] = hospital_df['Hospital Ownership'].replace({\n",
    "                    'Voluntary non-profit - Private': 'non-profit', \n",
    "                    'Proprietary':'for-profit', \n",
    "                    'Government - Hospital District or Authority': 'government',\n",
    "                    'Voluntary non-profit - Other':'non-profit',\n",
    "                    'Government - Local':'government',\n",
    "                    'Voluntary non-profit - Church':'non-profit',\n",
    "                    'Physician':'for-profit',\n",
    "                    'Government - State':'government',\n",
    "                    'Tribal ':'government',\n",
    "                    'Government - Federal':'government',\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hospital_df['Hospital Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four level in the following 7 aspect: \n",
    "Mortality national comparison; \n",
    "Safety of care national comparison;\n",
    "Safety of care national comparison;\n",
    "Readmission national comparison\tPatient experience national comparison\tEffectiveness of care national comparison\tTimeliness of care national comparison\tEfficient use of medical imaging national comparison\n",
    "-1 Below the national average\n",
    "0Same as the national average                    \n",
    "1Above the national average       \n",
    "Not Available   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are four level in the following 7 aspect\n",
    "#Same as the national average    \n",
    "#Not Available                   \n",
    "#Above the national average       \n",
    "#Below the national average\n",
    "hospital_df['Mortality national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Safety of care national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hospital_df['Readmission national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Safety of care national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Consolidate dataframes for ease of use\n",
    "#pd.concat()\n",
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Column\n",
    "food_df.rename(columns = {'Zipcode': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join food to PS data (want to make sure keep as much data as possible)\n",
    "PS_food_df = PS_df.merge(food_df, on=\"ZIP\", how=\"left\") \n",
    "PS_food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename SBUX and TGT columns\n",
    "SBUX_df.rename(columns = {'Postcode': 'ZIP'}, inplace=True)\n",
    "TGT_df.rename(columns = {'PostalCode': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join TGT to SBUX\n",
    "SBUX_TGT_df = SBUX_df.merge(TGT_df, on=\"ZIP\", how=\"left\")\n",
    "SBUX_TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = PS_food_df.merge(SBUX_TGT_df, on=\"ZIP\", how=\"left\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Reduction & Quick Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "https://pypi.org/project/autoimpute/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(test as much algorithm as possible, possible models include Random Forest, Gradient Boosting, Ada-Boosting, Voting Classifier...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Randome search training for parameters found in following article: \n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "#### Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#### Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.05, 0.10, 0.13, 0.15, 0.20, 0.26, 0.5]\n",
    "\n",
    "#### Create the random grid\n",
    "random_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}\n",
    "pprint(random_grid)\n",
    "\n",
    "#### Use the random grid to search for best hyperparameters\n",
    "#### First create the base model to tune\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "#### Random search of parameters, using 10 fold cross validation, \n",
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, cv = 10, random_state=3, n_jobs = -1)\n",
    "#dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=3, n_jobs = -1)\n",
    "\n",
    "#### Fit the random search model\n",
    "dt_random.fit(X_train, y_train)\n",
    "\n",
    "#### See what best parameters from fitting the random search: \n",
    "dt_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
