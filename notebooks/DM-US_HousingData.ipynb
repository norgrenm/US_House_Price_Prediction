{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project\n",
    "### By:  Group 3: Elio Aybar, Cristal Garcia, Sunny Li, Matt Norgren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages to import\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "pd.set_option('display.max_columns', 100) # Setting pandas to display a N number of columns\n",
    "pd.set_option('display.max_rows', 10) # Setting pandas to display a N number rows\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,VotingClassifier,BaggingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from hypopt import GridSearch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron,SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAN\\OneDrive - The University of Chicago\\2020_Autumn\\Data Mining Platforms [MSCA 31008]\\Group_Project\n"
     ]
    }
   ],
   "source": [
    "### IMPORT SET\n",
    "\n",
    "#Change working directory to match where the large files are stored\n",
    "# it is not best practice to centrally store files this large - although\n",
    "# git LFS should be explored\n",
    "\n",
    "### CWD -  MAN\n",
    "%cd \"C:\\Users\\MAN\\OneDrive - The University of Chicago\\2020_Autumn\\Data Mining Platforms [MSCA 31008]\\Group_Project\\\"\n",
    "## CWD - Cristal\n",
    "#%cd \"C:\\Users\\cgarc\\OneDrive - The University of Chicago\\GitHub\\US_HousingData-\\docs\"\n",
    "#cd\n",
    "## CWD - Elio \n",
    "#%cd \"C:\\Users\\Tipo\\Desktop\\GitHub\\Project\"\n",
    "## CWD - Sunny\n",
    "#%cd \"/Users/sunny/Data mining/final project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Establish Pandas Data Frames / Import\n",
    "\n",
    "### Zillow Set- Zip \n",
    "zip_df = pd.read_csv('Zip_time_series.csv', index_col = 'Date')  ### Issues with NaN on import\n",
    "\n",
    "## Public School Ratings \n",
    "PS_df = pd.read_csv('Public_Schools.csv')\n",
    "\n",
    "## Starbucks Upto 2017 for 70 Countries\n",
    "SBUX_df = pd.read_csv('directory.csv')\n",
    "\n",
    "## Food Desert \n",
    "foodlookup_df = pd.read_csv('food_access_variable_lookup.csv')\n",
    "food_df = pd.read_csv('food_access_research_atlas.csv') \n",
    "\n",
    "## Hospital Quality Care \n",
    "hospital_df = pd.read_csv('Hospital General Information.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "## Target Up to 2017 for US \n",
    "TGT_df = pd.read_csv('target.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Set Cleaning (Preparing for Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72864, 147)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "## Food Desert -- Cleaning CG  #\n",
    "################################\n",
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to drop\n",
    "food_df.drop(['GroupQuartersFlag', 'NUMGQTRS', 'PCTGQTRS', 'LILATracts_Vehicle',  'LATractsVehicle_20', 'LAPOP1_10', 'LAPOP05_10', 'LAPOP1_20', 'LALOWI1_10', 'LALOWI05_10', 'LALOWI1_20', 'lapophalf', 'lapophalfshare', 'lalowihalf', 'lalowihalfshare', 'lakidshalf', 'lakidshalfshare', 'laseniorshalf', 'laseniorshalfshare', 'lawhitehalf', 'lawhitehalfshare', 'lablackhalf', 'lablackhalfshare', 'laasianhalf', 'laasianhalfshare'], axis = 1, inplace = True)\n",
    "food_df.drop(['lanhopihalf', 'lanhopihalfshare', 'laaianhalf', 'laaianhalfshare', 'laomultirhalf', 'laomultirhalfshare', 'lahisphalf', 'lahisphalfshare', 'lahunvhalf', 'lahunvhalfshare', 'lasnaphalf', 'lasnaphalfshare', 'lapop1', 'lapop1share', 'lalowi1', 'lalowi1share', 'lakids1', 'lakids1share', 'laseniors1', 'laseniors1share', 'lawhite1', 'lawhite1share', 'lablack1', 'lablack1share', 'laasian1', 'laasian1share', 'lanhopi1', 'lanhopi1share', 'laaian1', 'laaian1share', 'laomultir1', 'laomultir1share', 'lahisp1', 'lahisp1share', 'lahunv1', 'lahunv1share'], axis = 1, inplace = True)\n",
    "food_df.drop(['lasnap1', 'lasnap1share', 'lapop10', 'lapop10share', 'lalowi10', 'lalowi10share', 'lakids10', 'lakids10share', 'laseniors10', 'laseniors10share', 'lawhite10', 'lawhite10share', 'lablack10', 'lablack10share', 'laasian10', 'laasian10share', 'lanhopi10', 'lanhopi10share', 'laaian10', 'laaian10share', 'laomultir10', 'laomultir10share', 'lahisp10', 'lahisp10share', 'lahunv10', 'lahunv10share', 'lasnap10', 'lasnap10share', 'lapop20', 'lapop20share', 'lalowi20', 'lalowi20share', 'lakids20', 'lakids20share', 'laseniors20', 'laseniors20share'], axis = 1, inplace = True)\n",
    "food_df.drop(['lawhite20', 'lawhite20share', 'lablack20', 'lablack20share', 'laasian20', 'laasian20share', 'lanhopi20', 'lanhopi20share', 'laaian20', 'laaian20share', 'laomultir20', 'laomultir20share', 'lahisp20', 'lahisp20share', 'lahunv20', 'lahunv20share'], axis = 1, inplace = True)\n",
    "food_df.drop(['LILATracts_1And10', 'LILATracts_halfAnd10', 'LILATracts_1And20', 'HUNVFlag', 'lasnap20', 'lasnap20share', 'TractLOWI', 'TractKids', 'TractSeniors', 'TractWhite', 'TractBlack', 'TractAsian', 'TractNHOPI', 'TractAIAN', 'TractOMultir', 'TractHispanic', 'TractHUNV', 'TractSNAP'], axis = 1, inplace = True)\n",
    "food_df.drop(['LAhalfand10', 'LA1and20', 'LATracts_half', 'LATracts1', 'LATracts10', 'LATracts20'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplication rows\n",
    "food_df.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Zipcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Zipcode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b3096d6c7ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#couldn't be identified and were replaced with NA's. Drop these respective rows with NA's in zipcode because those aren't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#functional censustract numbers and the rows also have 0's for more than 70% of columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfood_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfood_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfood_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Zipcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Zipcode'"
     ]
    }
   ],
   "source": [
    "#There are rows in the data with censustract numbers that no longer apply and the respective row has zero values. Zipcodes \n",
    "#couldn't be identified and were replaced with NA's. Drop these respective rows with NA's in zipcode because those aren't \n",
    "#functional censustract numbers and the rows also have 0's for more than 70% of columns\n",
    "food_df = food_df[food_df['Zipcode'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values\n",
    "food_df.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique values\n",
    "food_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Visually represent collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(food_df.corr(),annot=True,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Zipcode and find the average of features\n",
    "food_df = food_df.groupby('Zipcode', as_index=False)['Urban', 'POP2010', 'OHU2010', 'LowIncomeTracts', 'PovertyRate', 'MedianFamilyIncome', 'LA1and10'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "## Public School Ratings (2014-2015 School years) -- Cleaning CG  ##\n",
    "####################################################################\n",
    "\n",
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'LEVEL_' to change to integer (1: elementary, 2: middle school, 3: high school, 4:PK-13, N=0: Not specified)\n",
    "PS_df['LEVEL_'] = PS_df['LEVEL_'].apply({'N':0, '1':1, '2':2, '3':3, '4':4 }.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ZIP4 because 43% of data missing and already have other location indicators; don't need Telephone, website, source, \n",
    "#'VAL_METHOD', 'NAICS_CODE'; 'NAICS_DESC' is generalized description of 'LEVEL'; SHELTER_ID doesn't have 76% of data available \n",
    "\n",
    "PS_df.drop(['X', 'Y', 'OBJECTID', 'NCESID', 'ZIP4', 'TELEPHONE', 'NAICS_CODE', 'NAICS_DESC', 'SOURCE', 'VAL_METHOD', 'VAL_DATE',  'WEBSITE', 'ST_GRADE', 'END_GRADE', 'DISTRICTID',  'SHELTER_ID'], axis = 1, inplace = True)\n",
    "\n",
    "#Drop Puerto Rico location\n",
    "PS_df = PS_df[PS_df.COUNTRY != 'PRI']\n",
    "\n",
    "#Drop Country column since all inland\n",
    "PS_df.drop(['COUNTRY'], axis = 1, inplace = True)\n",
    "\n",
    "#Convert SOURCEDATE to actual datatime type\n",
    "PS_df['SOURCEDATE'] = pd.to_datetime(PS_df['SOURCEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplication rows\n",
    "PS_df.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop schools with 0 and negative enrolment\n",
    "PS_df = PS_df[PS_df.ENROLLMENT > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop schools with 0 and negative count of teachers\n",
    "PS_df = PS_df[PS_df.FT_TEACHER > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Student: Teacher ratio based on enrollment and Teacher count. 30:1 is the ideal ratio \n",
    "PS_df['Class_Teacher_RATIO'] = PS_df['ENROLLMENT'] / PS_df['FT_TEACHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#Visually represent collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(PS_df.corr(),annot=True,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Population, Enrollment, and FT_Teacher columns since they have collinearity and enrollment and FT_teacher included in \n",
    "#Class_Teacher_RATIO\n",
    "PS_df.drop(['POPULATION', 'ENROLLMENT', 'FT_TEACHER'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Zipcode and find avg of features per zipcode\n",
    "PS_df = PS_df.groupby('ZIP', as_index=False)['TYPE', 'STATUS', 'LEVEL_', 'Class_Teacher_RATIO'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Target -- Cleaning EA #\n",
    "##########################\n",
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select desired variables\n",
    "TGT_df = TGT_df[['Address.FormattedAddress','Address.AddressLine1','Address.City','Address.CountryName','Address.Latitude','Address.Longitude','Address.County','Address.PostalCode','Address.Subdivision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analize variable information\n",
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(TGT_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change variable names\n",
    "TGT_df = TGT_df.rename(columns={\"Address.FormattedAddress\": \"FormattedAddress\", \n",
    "                   \"Address.AddressLine1\": \"AddressLine1\",\n",
    "                   \"Address.City\": \"City\",\n",
    "                   \"Address.CountryName\": \"CountryName\",\n",
    "                   \"Address.Latitude\": \"Latitude\",\n",
    "                   \"Address.Longitude\": \"Longitude\",\n",
    "                   \"Address.County\": \"County\",\n",
    "                   \"Address.PostalCode\": \"PostalCode\",\n",
    "                   \"Address.Subdivision\": \"Subdivision\",\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values in column County variable\n",
    "TGT_df = TGT_df[TGT_df.County.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(TGT_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column that identifies Target at specified address (will groupby zipcode and count the number of targets by zipcode)\n",
    "TGT_df['Target_count'] = 1\n",
    "TGT_df = TGT_df.groupby('PostalCode', as_index=False)['Target_count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull shortened zipcode for Target data\n",
    "TGT_df['PostalCode'] = [x[:5] for x in TGT_df['PostalCode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert values to integers\n",
    "TGT_df['PostalCode'] = TGT_df.PostalCode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Starbucks -- Cleaning EA #\n",
    "#############################\n",
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1 = SBUX_df['Brand']\n",
    "print(A_1.groupby(A_1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_2 = SBUX_df['Country']\n",
    "print(A_2.groupby(A_2).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df[SBUX_df[\"Brand\"] == 'Starbucks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df[SBUX_df[\"Country\"] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select desired variables\n",
    "SBUX_df = SBUX_df[['Brand','Street Address','City','State/Province','Country','Postcode','Longitude','Latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(SBUX_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing values in column County variable\n",
    "SBUX_df = SBUX_df[SBUX_df.Postcode .notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of nan values in each column\n",
    "print(SBUX_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column that identifies Starbucks at specified address (will groupby zipcode and count the number of targets by zipcode)\n",
    "SBUX_df['Starbucks_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SBUX_df.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull shortened zipcode for Starbucks data\n",
    "SBUX_df['Postcode'] = [x[:5] for x in SBUX_df['Postcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df = SBUX_df.groupby('Postcode', as_index=False)['Starbucks_count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert values to integers\n",
    "SBUX_df['Postcode']= SBUX_df.Postcode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>InventorySeasonallyAdjusted_AllHomes</th>\n",
       "      <th>InventoryRaw_AllHomes</th>\n",
       "      <th>MedianListingPricePerSqft_1Bedroom</th>\n",
       "      <th>MedianListingPricePerSqft_2Bedroom</th>\n",
       "      <th>MedianListingPricePerSqft_3Bedroom</th>\n",
       "      <th>MedianListingPricePerSqft_4Bedroom</th>\n",
       "      <th>MedianListingPricePerSqft_5BedroomOrMore</th>\n",
       "      <th>MedianListingPricePerSqft_AllHomes</th>\n",
       "      <th>MedianListingPricePerSqft_CondoCoop</th>\n",
       "      <th>MedianListingPricePerSqft_DuplexTriplex</th>\n",
       "      <th>MedianListingPricePerSqft_SingleFamilyResidence</th>\n",
       "      <th>MedianListingPrice_1Bedroom</th>\n",
       "      <th>MedianListingPrice_2Bedroom</th>\n",
       "      <th>MedianListingPrice_3Bedroom</th>\n",
       "      <th>MedianListingPrice_4Bedroom</th>\n",
       "      <th>MedianListingPrice_5BedroomOrMore</th>\n",
       "      <th>MedianListingPrice_AllHomes</th>\n",
       "      <th>MedianListingPrice_CondoCoop</th>\n",
       "      <th>MedianListingPrice_DuplexTriplex</th>\n",
       "      <th>MedianListingPrice_SingleFamilyResidence</th>\n",
       "      <th>MedianPctOfPriceReduction_AllHomes</th>\n",
       "      <th>MedianPctOfPriceReduction_CondoCoop</th>\n",
       "      <th>MedianPctOfPriceReduction_SingleFamilyResidence</th>\n",
       "      <th>MedianPriceCutDollar_AllHomes</th>\n",
       "      <th>MedianPriceCutDollar_CondoCoop</th>\n",
       "      <th>MedianPriceCutDollar_SingleFamilyResidence</th>\n",
       "      <th>MedianRentalPricePerSqft_1Bedroom</th>\n",
       "      <th>MedianRentalPricePerSqft_2Bedroom</th>\n",
       "      <th>MedianRentalPricePerSqft_3Bedroom</th>\n",
       "      <th>MedianRentalPricePerSqft_4Bedroom</th>\n",
       "      <th>MedianRentalPricePerSqft_5BedroomOrMore</th>\n",
       "      <th>MedianRentalPricePerSqft_AllHomes</th>\n",
       "      <th>MedianRentalPricePerSqft_CondoCoop</th>\n",
       "      <th>MedianRentalPricePerSqft_DuplexTriplex</th>\n",
       "      <th>MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits</th>\n",
       "      <th>MedianRentalPricePerSqft_SingleFamilyResidence</th>\n",
       "      <th>MedianRentalPricePerSqft_Studio</th>\n",
       "      <th>MedianRentalPrice_1Bedroom</th>\n",
       "      <th>MedianRentalPrice_2Bedroom</th>\n",
       "      <th>MedianRentalPrice_3Bedroom</th>\n",
       "      <th>MedianRentalPrice_4Bedroom</th>\n",
       "      <th>MedianRentalPrice_5BedroomOrMore</th>\n",
       "      <th>MedianRentalPrice_AllHomes</th>\n",
       "      <th>MedianRentalPrice_CondoCoop</th>\n",
       "      <th>MedianRentalPrice_DuplexTriplex</th>\n",
       "      <th>MedianRentalPrice_MultiFamilyResidence5PlusUnits</th>\n",
       "      <th>MedianRentalPrice_SingleFamilyResidence</th>\n",
       "      <th>MedianRentalPrice_Studio</th>\n",
       "      <th>ZHVIPerSqft_AllHomes</th>\n",
       "      <th>PctOfHomesDecreasingInValues_AllHomes</th>\n",
       "      <th>PctOfHomesIncreasingInValues_AllHomes</th>\n",
       "      <th>PctOfListingsWithPriceReductionsSeasAdj_AllHomes</th>\n",
       "      <th>PctOfListingsWithPriceReductionsSeasAdj_CondoCoop</th>\n",
       "      <th>PctOfListingsWithPriceReductionsSeasAdj_SingleFamilyResidence</th>\n",
       "      <th>PctOfListingsWithPriceReductions_AllHomes</th>\n",
       "      <th>PctOfListingsWithPriceReductions_CondoCoop</th>\n",
       "      <th>PctOfListingsWithPriceReductions_SingleFamilyResidence</th>\n",
       "      <th>PriceToRentRatio_AllHomes</th>\n",
       "      <th>ZHVI_1bedroom</th>\n",
       "      <th>ZHVI_2bedroom</th>\n",
       "      <th>ZHVI_3bedroom</th>\n",
       "      <th>ZHVI_4bedroom</th>\n",
       "      <th>ZHVI_5BedroomOrMore</th>\n",
       "      <th>ZHVI_AllHomes</th>\n",
       "      <th>ZHVI_BottomTier</th>\n",
       "      <th>ZHVI_CondoCoop</th>\n",
       "      <th>ZHVI_MiddleTier</th>\n",
       "      <th>ZHVI_SingleFamilyResidence</th>\n",
       "      <th>ZHVI_TopTier</th>\n",
       "      <th>ZRI_AllHomes</th>\n",
       "      <th>ZRI_AllHomesPlusMultifamily</th>\n",
       "      <th>ZriPerSqft_AllHomes</th>\n",
       "      <th>Zri_MultiFamilyResidenceRental</th>\n",
       "      <th>Zri_SingleFamilyResidenceRental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.383885e+06</td>\n",
       "      <td>1.051104e+06</td>\n",
       "      <td>1.051104e+06</td>\n",
       "      <td>8194.000000</td>\n",
       "      <td>86554.000000</td>\n",
       "      <td>384738.000000</td>\n",
       "      <td>197581.000000</td>\n",
       "      <td>33722.000000</td>\n",
       "      <td>814908.000000</td>\n",
       "      <td>72778.000000</td>\n",
       "      <td>8092.000000</td>\n",
       "      <td>776613.000000</td>\n",
       "      <td>7.753000e+03</td>\n",
       "      <td>6.772400e+04</td>\n",
       "      <td>3.171890e+05</td>\n",
       "      <td>1.616000e+05</td>\n",
       "      <td>2.770300e+04</td>\n",
       "      <td>6.273190e+05</td>\n",
       "      <td>5.564600e+04</td>\n",
       "      <td>1.017100e+04</td>\n",
       "      <td>6.104810e+05</td>\n",
       "      <td>686488.000000</td>\n",
       "      <td>40040.000000</td>\n",
       "      <td>642488.000000</td>\n",
       "      <td>6.864880e+05</td>\n",
       "      <td>40040.000000</td>\n",
       "      <td>6.424880e+05</td>\n",
       "      <td>19600.000000</td>\n",
       "      <td>36378.000000</td>\n",
       "      <td>33054.000000</td>\n",
       "      <td>3814.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>120843.000000</td>\n",
       "      <td>18513.000000</td>\n",
       "      <td>4930.000000</td>\n",
       "      <td>69475.000000</td>\n",
       "      <td>82976.000000</td>\n",
       "      <td>24118.000000</td>\n",
       "      <td>30994.000000</td>\n",
       "      <td>47604.000000</td>\n",
       "      <td>39366.000000</td>\n",
       "      <td>5174.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>114535.000000</td>\n",
       "      <td>21156.000000</td>\n",
       "      <td>14691.000000</td>\n",
       "      <td>89954.000000</td>\n",
       "      <td>80475.000000</td>\n",
       "      <td>27734.000000</td>\n",
       "      <td>3.569675e+06</td>\n",
       "      <td>2.875664e+06</td>\n",
       "      <td>2.875664e+06</td>\n",
       "      <td>895136.000000</td>\n",
       "      <td>74272.000000</td>\n",
       "      <td>844536.000000</td>\n",
       "      <td>895136.000000</td>\n",
       "      <td>74272.000000</td>\n",
       "      <td>844536.000000</td>\n",
       "      <td>1.280862e+06</td>\n",
       "      <td>5.123590e+05</td>\n",
       "      <td>2.333191e+06</td>\n",
       "      <td>3.195020e+06</td>\n",
       "      <td>2.627774e+06</td>\n",
       "      <td>1.313837e+06</td>\n",
       "      <td>3.638221e+06</td>\n",
       "      <td>3.073015e+06</td>\n",
       "      <td>1.296485e+06</td>\n",
       "      <td>3.631566e+06</td>\n",
       "      <td>3.612063e+06</td>\n",
       "      <td>3.684376e+06</td>\n",
       "      <td>1.337362e+06</td>\n",
       "      <td>1.339353e+06</td>\n",
       "      <td>1.253969e+06</td>\n",
       "      <td>723542.000000</td>\n",
       "      <td>1.334321e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.683726e+04</td>\n",
       "      <td>1.230490e+02</td>\n",
       "      <td>1.230721e+02</td>\n",
       "      <td>322.914946</td>\n",
       "      <td>188.769142</td>\n",
       "      <td>144.331279</td>\n",
       "      <td>154.549637</td>\n",
       "      <td>223.571617</td>\n",
       "      <td>158.755338</td>\n",
       "      <td>273.766816</td>\n",
       "      <td>228.069518</td>\n",
       "      <td>150.567647</td>\n",
       "      <td>2.630217e+05</td>\n",
       "      <td>2.388086e+05</td>\n",
       "      <td>2.470818e+05</td>\n",
       "      <td>3.937908e+05</td>\n",
       "      <td>8.394086e+05</td>\n",
       "      <td>2.785605e+05</td>\n",
       "      <td>3.102841e+05</td>\n",
       "      <td>4.966216e+05</td>\n",
       "      <td>2.896942e+05</td>\n",
       "      <td>4.213423</td>\n",
       "      <td>4.501746</td>\n",
       "      <td>4.195601</td>\n",
       "      <td>9.834591e+03</td>\n",
       "      <td>12069.728272</td>\n",
       "      <td>1.013018e+04</td>\n",
       "      <td>2.334064</td>\n",
       "      <td>1.698105</td>\n",
       "      <td>1.055774</td>\n",
       "      <td>1.078680</td>\n",
       "      <td>4.719254</td>\n",
       "      <td>1.207743</td>\n",
       "      <td>2.136242</td>\n",
       "      <td>2.697142</td>\n",
       "      <td>1.719023</td>\n",
       "      <td>1.019034</td>\n",
       "      <td>1.353846</td>\n",
       "      <td>1704.562173</td>\n",
       "      <td>1819.981388</td>\n",
       "      <td>1781.532744</td>\n",
       "      <td>2549.728740</td>\n",
       "      <td>4412.232890</td>\n",
       "      <td>1635.881429</td>\n",
       "      <td>2064.212257</td>\n",
       "      <td>2092.248349</td>\n",
       "      <td>1556.011133</td>\n",
       "      <td>1571.055092</td>\n",
       "      <td>1529.596290</td>\n",
       "      <td>1.246145e+02</td>\n",
       "      <td>3.466598e+01</td>\n",
       "      <td>5.795258e+01</td>\n",
       "      <td>12.938144</td>\n",
       "      <td>11.275611</td>\n",
       "      <td>13.235967</td>\n",
       "      <td>12.923149</td>\n",
       "      <td>11.260929</td>\n",
       "      <td>13.219574</td>\n",
       "      <td>1.116679e+01</td>\n",
       "      <td>1.590071e+05</td>\n",
       "      <td>1.593707e+05</td>\n",
       "      <td>1.987462e+05</td>\n",
       "      <td>2.779433e+05</td>\n",
       "      <td>4.438180e+05</td>\n",
       "      <td>1.976345e+05</td>\n",
       "      <td>1.485749e+05</td>\n",
       "      <td>1.877266e+05</td>\n",
       "      <td>1.977040e+05</td>\n",
       "      <td>2.079495e+05</td>\n",
       "      <td>2.932095e+05</td>\n",
       "      <td>1.429688e+03</td>\n",
       "      <td>1.414117e+03</td>\n",
       "      <td>9.484601e-01</td>\n",
       "      <td>1325.079733</td>\n",
       "      <td>1.463457e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.883334e+04</td>\n",
       "      <td>1.172875e+02</td>\n",
       "      <td>1.180173e+02</td>\n",
       "      <td>301.027216</td>\n",
       "      <td>186.646266</td>\n",
       "      <td>115.581365</td>\n",
       "      <td>114.846920</td>\n",
       "      <td>216.186771</td>\n",
       "      <td>134.386742</td>\n",
       "      <td>290.412769</td>\n",
       "      <td>195.983474</td>\n",
       "      <td>105.408294</td>\n",
       "      <td>2.307051e+05</td>\n",
       "      <td>2.557611e+05</td>\n",
       "      <td>2.421257e+05</td>\n",
       "      <td>3.553844e+05</td>\n",
       "      <td>1.117868e+06</td>\n",
       "      <td>2.501648e+05</td>\n",
       "      <td>3.303760e+05</td>\n",
       "      <td>4.068856e+05</td>\n",
       "      <td>2.767894e+05</td>\n",
       "      <td>2.040705</td>\n",
       "      <td>2.066104</td>\n",
       "      <td>2.064019</td>\n",
       "      <td>1.204638e+04</td>\n",
       "      <td>16052.952737</td>\n",
       "      <td>1.405195e+04</td>\n",
       "      <td>0.988807</td>\n",
       "      <td>0.820759</td>\n",
       "      <td>0.589681</td>\n",
       "      <td>2.071355</td>\n",
       "      <td>6.520360</td>\n",
       "      <td>0.898108</td>\n",
       "      <td>1.201135</td>\n",
       "      <td>1.226605</td>\n",
       "      <td>0.847736</td>\n",
       "      <td>0.851736</td>\n",
       "      <td>1.194078</td>\n",
       "      <td>711.002461</td>\n",
       "      <td>898.925776</td>\n",
       "      <td>1527.628002</td>\n",
       "      <td>3605.737742</td>\n",
       "      <td>3786.721933</td>\n",
       "      <td>926.822707</td>\n",
       "      <td>905.313341</td>\n",
       "      <td>777.665515</td>\n",
       "      <td>682.425639</td>\n",
       "      <td>1229.319601</td>\n",
       "      <td>577.014372</td>\n",
       "      <td>1.009763e+02</td>\n",
       "      <td>2.788985e+01</td>\n",
       "      <td>2.913422e+01</td>\n",
       "      <td>4.683065</td>\n",
       "      <td>4.820278</td>\n",
       "      <td>4.767322</td>\n",
       "      <td>5.249719</td>\n",
       "      <td>5.249506</td>\n",
       "      <td>5.358528</td>\n",
       "      <td>3.626782e+00</td>\n",
       "      <td>1.246349e+05</td>\n",
       "      <td>1.367514e+05</td>\n",
       "      <td>1.688202e+05</td>\n",
       "      <td>2.392152e+05</td>\n",
       "      <td>4.454901e+05</td>\n",
       "      <td>1.772286e+05</td>\n",
       "      <td>1.240348e+05</td>\n",
       "      <td>1.426228e+05</td>\n",
       "      <td>1.771804e+05</td>\n",
       "      <td>2.040974e+05</td>\n",
       "      <td>2.970779e+05</td>\n",
       "      <td>7.197163e+02</td>\n",
       "      <td>6.913265e+02</td>\n",
       "      <td>4.240444e-01</td>\n",
       "      <td>568.827402</td>\n",
       "      <td>8.077924e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.450000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>24.793388</td>\n",
       "      <td>21.045918</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>21.384804</td>\n",
       "      <td>19.370574</td>\n",
       "      <td>15.716151</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>16.987139</td>\n",
       "      <td>15.716151</td>\n",
       "      <td>1.990000e+04</td>\n",
       "      <td>2.619800e+04</td>\n",
       "      <td>2.942600e+04</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>3.375000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>2.525000e+04</td>\n",
       "      <td>3.310000e+04</td>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.720708</td>\n",
       "      <td>0.485884</td>\n",
       "      <td>0.505859</td>\n",
       "      <td>0.531226</td>\n",
       "      <td>0.672194</td>\n",
       "      <td>0.430228</td>\n",
       "      <td>0.575506</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.501520</td>\n",
       "      <td>0.430228</td>\n",
       "      <td>0.428897</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>512.500000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>497.500000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>512.500000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.922714</td>\n",
       "      <td>-4.569741</td>\n",
       "      <td>-4.271567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.900000e-01</td>\n",
       "      <td>2.130000e+04</td>\n",
       "      <td>1.560000e+04</td>\n",
       "      <td>2.460000e+04</td>\n",
       "      <td>2.050000e+04</td>\n",
       "      <td>2.670000e+04</td>\n",
       "      <td>1.670000e+04</td>\n",
       "      <td>1.350000e+04</td>\n",
       "      <td>2.700000e+04</td>\n",
       "      <td>1.670000e+04</td>\n",
       "      <td>1.670000e+04</td>\n",
       "      <td>2.690000e+04</td>\n",
       "      <td>4.110000e+02</td>\n",
       "      <td>4.110000e+02</td>\n",
       "      <td>2.760000e-01</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>4.110000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.183000e+04</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>155.056896</td>\n",
       "      <td>97.826937</td>\n",
       "      <td>91.187739</td>\n",
       "      <td>99.996853</td>\n",
       "      <td>109.830759</td>\n",
       "      <td>92.095406</td>\n",
       "      <td>122.861795</td>\n",
       "      <td>66.036579</td>\n",
       "      <td>91.339016</td>\n",
       "      <td>1.150000e+05</td>\n",
       "      <td>1.179000e+05</td>\n",
       "      <td>1.449000e+05</td>\n",
       "      <td>2.429980e+05</td>\n",
       "      <td>3.498600e+05</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>1.499000e+05</td>\n",
       "      <td>1.890000e+05</td>\n",
       "      <td>1.525000e+05</td>\n",
       "      <td>2.893159</td>\n",
       "      <td>3.115176</td>\n",
       "      <td>2.860296</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>5034.625000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.616905</td>\n",
       "      <td>1.119909</td>\n",
       "      <td>0.756266</td>\n",
       "      <td>0.692921</td>\n",
       "      <td>0.722525</td>\n",
       "      <td>0.765527</td>\n",
       "      <td>1.266798</td>\n",
       "      <td>1.811408</td>\n",
       "      <td>1.130952</td>\n",
       "      <td>0.729755</td>\n",
       "      <td>0.735782</td>\n",
       "      <td>1211.250000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>1550.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>1.106000e+01</td>\n",
       "      <td>3.551000e+01</td>\n",
       "      <td>9.674628</td>\n",
       "      <td>7.870348</td>\n",
       "      <td>9.902918</td>\n",
       "      <td>9.202454</td>\n",
       "      <td>7.488987</td>\n",
       "      <td>9.411765</td>\n",
       "      <td>8.820000e+00</td>\n",
       "      <td>7.750000e+04</td>\n",
       "      <td>8.220000e+04</td>\n",
       "      <td>1.079000e+05</td>\n",
       "      <td>1.488000e+05</td>\n",
       "      <td>2.146000e+05</td>\n",
       "      <td>1.012000e+05</td>\n",
       "      <td>7.560000e+04</td>\n",
       "      <td>1.045000e+05</td>\n",
       "      <td>1.014000e+05</td>\n",
       "      <td>1.022000e+05</td>\n",
       "      <td>1.499000e+05</td>\n",
       "      <td>1.006000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>6.980000e-01</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1.007000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.466900e+04</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>230.835830</td>\n",
       "      <td>139.332358</td>\n",
       "      <td>117.742281</td>\n",
       "      <td>125.722509</td>\n",
       "      <td>147.375569</td>\n",
       "      <td>122.694639</td>\n",
       "      <td>184.293515</td>\n",
       "      <td>195.462073</td>\n",
       "      <td>120.910134</td>\n",
       "      <td>2.060000e+05</td>\n",
       "      <td>1.699990e+05</td>\n",
       "      <td>1.959000e+05</td>\n",
       "      <td>3.169900e+05</td>\n",
       "      <td>4.749495e+05</td>\n",
       "      <td>2.190000e+05</td>\n",
       "      <td>2.374000e+05</td>\n",
       "      <td>4.494950e+05</td>\n",
       "      <td>2.200000e+05</td>\n",
       "      <td>3.746356</td>\n",
       "      <td>4.038462</td>\n",
       "      <td>3.710575</td>\n",
       "      <td>7.650000e+03</td>\n",
       "      <td>9750.000000</td>\n",
       "      <td>7.700000e+03</td>\n",
       "      <td>2.108982</td>\n",
       "      <td>1.471973</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.760404</td>\n",
       "      <td>0.810443</td>\n",
       "      <td>0.929522</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>2.420914</td>\n",
       "      <td>1.494366</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.878184</td>\n",
       "      <td>1564.000000</td>\n",
       "      <td>1615.000000</td>\n",
       "      <td>1445.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>1447.500000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>1375.000000</td>\n",
       "      <td>1425.000000</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>2.793000e+01</td>\n",
       "      <td>6.207000e+01</td>\n",
       "      <td>12.722432</td>\n",
       "      <td>10.945674</td>\n",
       "      <td>12.997600</td>\n",
       "      <td>12.568306</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>12.840467</td>\n",
       "      <td>1.063000e+01</td>\n",
       "      <td>1.228000e+05</td>\n",
       "      <td>1.212000e+05</td>\n",
       "      <td>1.496000e+05</td>\n",
       "      <td>2.137000e+05</td>\n",
       "      <td>3.202000e+05</td>\n",
       "      <td>1.469000e+05</td>\n",
       "      <td>1.129000e+05</td>\n",
       "      <td>1.457000e+05</td>\n",
       "      <td>1.470000e+05</td>\n",
       "      <td>1.495000e+05</td>\n",
       "      <td>2.152000e+05</td>\n",
       "      <td>1.246000e+03</td>\n",
       "      <td>1.238000e+03</td>\n",
       "      <td>8.340000e-01</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1.251000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.271800e+04</td>\n",
       "      <td>1.600000e+02</td>\n",
       "      <td>1.600000e+02</td>\n",
       "      <td>380.292972</td>\n",
       "      <td>215.616002</td>\n",
       "      <td>160.705393</td>\n",
       "      <td>168.603216</td>\n",
       "      <td>241.664617</td>\n",
       "      <td>175.354721</td>\n",
       "      <td>312.237594</td>\n",
       "      <td>311.227307</td>\n",
       "      <td>170.726172</td>\n",
       "      <td>3.250000e+05</td>\n",
       "      <td>2.850000e+05</td>\n",
       "      <td>2.804000e+05</td>\n",
       "      <td>4.375000e+05</td>\n",
       "      <td>7.424500e+05</td>\n",
       "      <td>3.250000e+05</td>\n",
       "      <td>3.590000e+05</td>\n",
       "      <td>6.490000e+05</td>\n",
       "      <td>3.344500e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.405405</td>\n",
       "      <td>4.994572</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>11950.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>2.758255</td>\n",
       "      <td>2.079227</td>\n",
       "      <td>1.164020</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>5.479575</td>\n",
       "      <td>1.332650</td>\n",
       "      <td>2.590612</td>\n",
       "      <td>3.123734</td>\n",
       "      <td>2.067885</td>\n",
       "      <td>1.085403</td>\n",
       "      <td>1.288885</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2225.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>1895.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>1869.875000</td>\n",
       "      <td>1762.500000</td>\n",
       "      <td>1795.000000</td>\n",
       "      <td>1.430000e+02</td>\n",
       "      <td>5.330000e+01</td>\n",
       "      <td>8.297000e+01</td>\n",
       "      <td>15.946533</td>\n",
       "      <td>14.290810</td>\n",
       "      <td>16.292357</td>\n",
       "      <td>16.260163</td>\n",
       "      <td>14.482759</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>1.294000e+01</td>\n",
       "      <td>1.967000e+05</td>\n",
       "      <td>1.847000e+05</td>\n",
       "      <td>2.296000e+05</td>\n",
       "      <td>3.250000e+05</td>\n",
       "      <td>5.098000e+05</td>\n",
       "      <td>2.300000e+05</td>\n",
       "      <td>1.735000e+05</td>\n",
       "      <td>2.211000e+05</td>\n",
       "      <td>2.301000e+05</td>\n",
       "      <td>2.390000e+05</td>\n",
       "      <td>3.318000e+05</td>\n",
       "      <td>1.613000e+03</td>\n",
       "      <td>1.598000e+03</td>\n",
       "      <td>1.052000e+00</td>\n",
       "      <td>1549.000000</td>\n",
       "      <td>1.642000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.990100e+04</td>\n",
       "      <td>2.560000e+03</td>\n",
       "      <td>2.639000e+03</td>\n",
       "      <td>2128.129602</td>\n",
       "      <td>2746.913580</td>\n",
       "      <td>3167.641326</td>\n",
       "      <td>3364.485981</td>\n",
       "      <td>2310.628893</td>\n",
       "      <td>2799.423447</td>\n",
       "      <td>2802.346570</td>\n",
       "      <td>1209.056644</td>\n",
       "      <td>2077.205882</td>\n",
       "      <td>1.580000e+06</td>\n",
       "      <td>4.300000e+06</td>\n",
       "      <td>7.950000e+06</td>\n",
       "      <td>1.175000e+07</td>\n",
       "      <td>1.349250e+07</td>\n",
       "      <td>6.299000e+06</td>\n",
       "      <td>5.750000e+06</td>\n",
       "      <td>3.175000e+06</td>\n",
       "      <td>6.897500e+06</td>\n",
       "      <td>49.031211</td>\n",
       "      <td>41.860465</td>\n",
       "      <td>49.031211</td>\n",
       "      <td>2.525000e+06</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>1.497500e+06</td>\n",
       "      <td>6.248168</td>\n",
       "      <td>6.017505</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>19.696970</td>\n",
       "      <td>22.566872</td>\n",
       "      <td>7.175295</td>\n",
       "      <td>6.271643</td>\n",
       "      <td>6.208843</td>\n",
       "      <td>22.566872</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>4595.000000</td>\n",
       "      <td>7597.500000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>6950.000000</td>\n",
       "      <td>6595.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>2.041000e+03</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>43.218021</td>\n",
       "      <td>50.991518</td>\n",
       "      <td>43.224984</td>\n",
       "      <td>48.214286</td>\n",
       "      <td>55.681818</td>\n",
       "      <td>48.214286</td>\n",
       "      <td>7.170000e+01</td>\n",
       "      <td>1.717100e+06</td>\n",
       "      <td>3.365100e+06</td>\n",
       "      <td>5.506300e+06</td>\n",
       "      <td>6.712100e+06</td>\n",
       "      <td>1.088390e+07</td>\n",
       "      <td>7.212500e+06</td>\n",
       "      <td>3.872400e+06</td>\n",
       "      <td>3.083700e+06</td>\n",
       "      <td>7.212500e+06</td>\n",
       "      <td>7.313400e+06</td>\n",
       "      <td>1.296680e+07</td>\n",
       "      <td>1.837500e+04</td>\n",
       "      <td>1.780800e+04</td>\n",
       "      <td>6.496000e+00</td>\n",
       "      <td>15891.000000</td>\n",
       "      <td>2.096400e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionName  InventorySeasonallyAdjusted_AllHomes  InventoryRaw_AllHomes  MedianListingPricePerSqft_1Bedroom  MedianListingPricePerSqft_2Bedroom  MedianListingPricePerSqft_3Bedroom  MedianListingPricePerSqft_4Bedroom  MedianListingPricePerSqft_5BedroomOrMore  MedianListingPricePerSqft_AllHomes  MedianListingPricePerSqft_CondoCoop  MedianListingPricePerSqft_DuplexTriplex  MedianListingPricePerSqft_SingleFamilyResidence  MedianListingPrice_1Bedroom  MedianListingPrice_2Bedroom  MedianListingPrice_3Bedroom  MedianListingPrice_4Bedroom  MedianListingPrice_5BedroomOrMore  MedianListingPrice_AllHomes  MedianListingPrice_CondoCoop  MedianListingPrice_DuplexTriplex  MedianListingPrice_SingleFamilyResidence  MedianPctOfPriceReduction_AllHomes  MedianPctOfPriceReduction_CondoCoop  MedianPctOfPriceReduction_SingleFamilyResidence  MedianPriceCutDollar_AllHomes  MedianPriceCutDollar_CondoCoop  MedianPriceCutDollar_SingleFamilyResidence  MedianRentalPricePerSqft_1Bedroom  \\\n",
       "count  4.383885e+06                          1.051104e+06           1.051104e+06                         8194.000000                        86554.000000                       384738.000000                       197581.000000                              33722.000000                       814908.000000                         72778.000000                              8092.000000                                    776613.000000                 7.753000e+03                 6.772400e+04                 3.171890e+05                 1.616000e+05                       2.770300e+04                 6.273190e+05                  5.564600e+04                      1.017100e+04                              6.104810e+05                       686488.000000                         40040.000000                                    642488.000000                   6.864880e+05                    40040.000000                                6.424880e+05                       19600.000000   \n",
       "mean   4.683726e+04                          1.230490e+02           1.230721e+02                          322.914946                          188.769142                          144.331279                          154.549637                                223.571617                          158.755338                           273.766816                               228.069518                                       150.567647                 2.630217e+05                 2.388086e+05                 2.470818e+05                 3.937908e+05                       8.394086e+05                 2.785605e+05                  3.102841e+05                      4.966216e+05                              2.896942e+05                            4.213423                             4.501746                                         4.195601                   9.834591e+03                    12069.728272                                1.013018e+04                           2.334064   \n",
       "std    2.883334e+04                          1.172875e+02           1.180173e+02                          301.027216                          186.646266                          115.581365                          114.846920                                216.186771                          134.386742                           290.412769                               195.983474                                       105.408294                 2.307051e+05                 2.557611e+05                 2.421257e+05                 3.553844e+05                       1.117868e+06                 2.501648e+05                  3.303760e+05                      4.068856e+05                              2.767894e+05                            2.040705                             2.066104                                         2.064019                   1.204638e+04                    16052.952737                                1.405195e+04                           0.988807   \n",
       "min    7.450000e+02                          3.000000e+00           2.000000e+00                           24.793388                           21.045918                           20.833333                           21.384804                                 19.370574                           15.716151                            28.750000                                16.987139                                        15.716151                 1.990000e+04                 2.619800e+04                 2.942600e+04                 3.000000e+04                       3.375000e+04                 1.500000e+04                  2.525000e+04                      3.310000e+04                              1.500000e+04                            0.000035                             0.000226                                         0.000035                   1.000000e+00                        1.000000                                1.000000e+00                           0.720708   \n",
       "25%    2.183000e+04                          4.600000e+01           4.600000e+01                          155.056896                           97.826937                           91.187739                           99.996853                                109.830759                           92.095406                           122.861795                                66.036579                                        91.339016                 1.150000e+05                 1.179000e+05                 1.449000e+05                 2.429980e+05                       3.498600e+05                 1.500000e+05                  1.499000e+05                      1.890000e+05                              1.525000e+05                            2.893159                             3.115176                                         2.860296                   5.000000e+03                     5034.625000                                5.000000e+03                           1.616905   \n",
       "50%    4.466900e+04                          8.800000e+01           8.800000e+01                          230.835830                          139.332358                          117.742281                          125.722509                                147.375569                          122.694639                           184.293515                               195.462073                                       120.910134                 2.060000e+05                 1.699990e+05                 1.959000e+05                 3.169900e+05                       4.749495e+05                 2.190000e+05                  2.374000e+05                      4.494950e+05                              2.200000e+05                            3.746356                             4.038462                                         3.710575                   7.650000e+03                     9750.000000                                7.700000e+03                           2.108982   \n",
       "75%    7.271800e+04                          1.600000e+02           1.600000e+02                          380.292972                          215.616002                          160.705393                          168.603216                                241.664617                          175.354721                           312.237594                               311.227307                                       170.726172                 3.250000e+05                 2.850000e+05                 2.804000e+05                 4.375000e+05                       7.424500e+05                 3.250000e+05                  3.590000e+05                      6.490000e+05                              3.344500e+05                            5.000000                             5.405405                                         4.994572                   1.000000e+04                    11950.000000                                1.000000e+04                           2.758255   \n",
       "max    9.990100e+04                          2.560000e+03           2.639000e+03                         2128.129602                         2746.913580                         3167.641326                         3364.485981                               2310.628893                         2799.423447                          2802.346570                              1209.056644                                      2077.205882                 1.580000e+06                 4.300000e+06                 7.950000e+06                 1.175000e+07                       1.349250e+07                 6.299000e+06                  5.750000e+06                      3.175000e+06                              6.897500e+06                           49.031211                            41.860465                                        49.031211                   2.525000e+06                   500000.000000                                1.497500e+06                           6.248168   \n",
       "\n",
       "       MedianRentalPricePerSqft_2Bedroom  MedianRentalPricePerSqft_3Bedroom  MedianRentalPricePerSqft_4Bedroom  MedianRentalPricePerSqft_5BedroomOrMore  MedianRentalPricePerSqft_AllHomes  MedianRentalPricePerSqft_CondoCoop  MedianRentalPricePerSqft_DuplexTriplex  MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits  MedianRentalPricePerSqft_SingleFamilyResidence  MedianRentalPricePerSqft_Studio  MedianRentalPrice_1Bedroom  MedianRentalPrice_2Bedroom  MedianRentalPrice_3Bedroom  MedianRentalPrice_4Bedroom  MedianRentalPrice_5BedroomOrMore  MedianRentalPrice_AllHomes  MedianRentalPrice_CondoCoop  MedianRentalPrice_DuplexTriplex  MedianRentalPrice_MultiFamilyResidence5PlusUnits  MedianRentalPrice_SingleFamilyResidence  MedianRentalPrice_Studio  ZHVIPerSqft_AllHomes  PctOfHomesDecreasingInValues_AllHomes  PctOfHomesIncreasingInValues_AllHomes  PctOfListingsWithPriceReductionsSeasAdj_AllHomes  PctOfListingsWithPriceReductionsSeasAdj_CondoCoop  \\\n",
       "count                       36378.000000                       33054.000000                        3814.000000                               159.000000                      120843.000000                        18513.000000                             4930.000000                                       69475.000000                                          82976.000000                     24118.000000                30994.000000                47604.000000                39366.000000                 5174.000000                        526.000000               114535.000000                 21156.000000                     14691.000000                                      89954.000000                             80475.000000              27734.000000          3.569675e+06                           2.875664e+06                           2.875664e+06                                     895136.000000                                       74272.000000   \n",
       "mean                            1.698105                           1.055774                           1.078680                                 4.719254                           1.207743                            2.136242                                2.697142                                           1.719023                                              1.019034                         1.353846                 1704.562173                 1819.981388                 1781.532744                 2549.728740                       4412.232890                 1635.881429                  2064.212257                      2092.248349                                       1556.011133                              1571.055092               1529.596290          1.246145e+02                           3.466598e+01                           5.795258e+01                                         12.938144                                          11.275611   \n",
       "std                             0.820759                           0.589681                           2.071355                                 6.520360                           0.898108                            1.201135                                1.226605                                           0.847736                                              0.851736                         1.194078                  711.002461                  898.925776                 1527.628002                 3605.737742                       3786.721933                  926.822707                   905.313341                       777.665515                                        682.425639                              1229.319601                577.014372          1.009763e+02                           2.788985e+01                           2.913422e+01                                          4.683065                                           4.820278   \n",
       "min                             0.485884                           0.505859                           0.531226                                 0.672194                           0.430228                            0.575506                                0.518293                                           0.501520                                              0.430228                         0.428897                  420.000000                  451.000000                  550.000000                 1025.000000                       2400.000000                  512.500000                   650.000000                       497.500000                                        375.000000                               512.500000                600.000000          1.400000e+01                           0.000000e+00                           0.000000e+00                                         -3.922714                                          -4.569741   \n",
       "25%                             1.119909                           0.756266                           0.692921                                 0.722525                           0.765527                            1.266798                                1.811408                                           1.130952                                              0.729755                         0.735782                 1211.250000                 1200.000000                 1172.000000                 1600.000000                       3300.000000                 1150.000000                  1350.000000                      1550.000000                                       1074.000000                              1100.000000               1100.000000          6.900000e+01                           1.106000e+01                           3.551000e+01                                          9.674628                                           7.870348   \n",
       "50%                             1.471973                           0.885892                           0.760404                                 0.810443                           0.929522                            1.785714                                2.420914                                           1.494366                                              0.841346                         0.878184                 1564.000000                 1615.000000                 1445.000000                 1995.000000                       3975.000000                 1447.500000                  1875.000000                      2000.000000                                       1400.000000                              1375.000000               1425.000000          9.500000e+01                           2.793000e+01                           6.207000e+01                                         12.722432                                          10.945674   \n",
       "75%                             2.079227                           1.164020                           0.860556                                 5.479575                           1.332650                            2.590612                                3.123734                                           2.067885                                              1.085403                         1.288885                 2000.000000                 2225.000000                 2000.000000                 2700.000000                       4500.000000                 1895.000000                  2595.000000                      2600.000000                                       1869.875000                              1762.500000               1795.000000          1.430000e+02                           5.330000e+01                           8.297000e+01                                         15.946533                                          14.290810   \n",
       "max                             6.017505                          18.000000                          25.000000                                19.696970                          22.566872                            7.175295                                6.271643                                           6.208843                                             22.566872                         7.142857                 4595.000000                 7597.500000                45000.000000                50000.000000                      35000.000000                50000.000000                  8500.000000                      6950.000000                                       6595.000000                             50000.000000               6000.000000          2.041000e+03                           1.000000e+02                           1.000000e+02                                         43.218021                                          50.991518   \n",
       "\n",
       "       PctOfListingsWithPriceReductionsSeasAdj_SingleFamilyResidence  PctOfListingsWithPriceReductions_AllHomes  PctOfListingsWithPriceReductions_CondoCoop  PctOfListingsWithPriceReductions_SingleFamilyResidence  PriceToRentRatio_AllHomes  ZHVI_1bedroom  ZHVI_2bedroom  ZHVI_3bedroom  ZHVI_4bedroom  ZHVI_5BedroomOrMore  ZHVI_AllHomes  ZHVI_BottomTier  ZHVI_CondoCoop  ZHVI_MiddleTier  ZHVI_SingleFamilyResidence  ZHVI_TopTier  ZRI_AllHomes  ZRI_AllHomesPlusMultifamily  ZriPerSqft_AllHomes  Zri_MultiFamilyResidenceRental  Zri_SingleFamilyResidenceRental  \n",
       "count                                      844536.000000                                          895136.000000                                74272.000000                                      844536.000000                    1.280862e+06   5.123590e+05   2.333191e+06   3.195020e+06   2.627774e+06         1.313837e+06   3.638221e+06     3.073015e+06    1.296485e+06     3.631566e+06                3.612063e+06  3.684376e+06  1.337362e+06                 1.339353e+06         1.253969e+06                   723542.000000                     1.334321e+06  \n",
       "mean                                           13.235967                                              12.923149                                   11.260929                                          13.219574                    1.116679e+01   1.590071e+05   1.593707e+05   1.987462e+05   2.779433e+05         4.438180e+05   1.976345e+05     1.485749e+05    1.877266e+05     1.977040e+05                2.079495e+05  2.932095e+05  1.429688e+03                 1.414117e+03         9.484601e-01                     1325.079733                     1.463457e+03  \n",
       "std                                             4.767322                                               5.249719                                    5.249506                                           5.358528                    3.626782e+00   1.246349e+05   1.367514e+05   1.688202e+05   2.392152e+05         4.454901e+05   1.772286e+05     1.240348e+05    1.426228e+05     1.771804e+05                2.040974e+05  2.970779e+05  7.197163e+02                 6.913265e+02         4.240444e-01                      568.827402                     8.077924e+02  \n",
       "min                                            -4.271567                                               0.000000                                    0.000000                                           0.000000                    4.900000e-01   2.130000e+04   1.560000e+04   2.460000e+04   2.050000e+04         2.670000e+04   1.670000e+04     1.350000e+04    2.700000e+04     1.670000e+04                1.670000e+04  2.690000e+04  4.110000e+02                 4.110000e+02         2.760000e-01                      414.000000                     4.110000e+02  \n",
       "25%                                             9.902918                                               9.202454                                    7.488987                                           9.411765                    8.820000e+00   7.750000e+04   8.220000e+04   1.079000e+05   1.488000e+05         2.146000e+05   1.012000e+05     7.560000e+04    1.045000e+05     1.014000e+05                1.022000e+05  1.499000e+05  1.006000e+03                 1.000000e+03         6.980000e-01                      933.000000                     1.007000e+03  \n",
       "50%                                            12.997600                                              12.568306                                   10.769231                                          12.840467                    1.063000e+01   1.228000e+05   1.212000e+05   1.496000e+05   2.137000e+05         3.202000e+05   1.469000e+05     1.129000e+05    1.457000e+05     1.470000e+05                1.495000e+05  2.152000e+05  1.246000e+03                 1.238000e+03         8.340000e-01                     1194.000000                     1.251000e+03  \n",
       "75%                                            16.292357                                              16.260163                                   14.482759                                          16.666667                    1.294000e+01   1.967000e+05   1.847000e+05   2.296000e+05   3.250000e+05         5.098000e+05   2.300000e+05     1.735000e+05    2.211000e+05     2.301000e+05                2.390000e+05  3.318000e+05  1.613000e+03                 1.598000e+03         1.052000e+00                     1549.000000                     1.642000e+03  \n",
       "max                                            43.224984                                              48.214286                                   55.681818                                          48.214286                    7.170000e+01   1.717100e+06   3.365100e+06   5.506300e+06   6.712100e+06         1.088390e+07   7.212500e+06     3.872400e+06    3.083700e+06     7.212500e+06                7.313400e+06  1.296680e+07  1.837500e+04                 1.780800e+04         6.496000e+00                    15891.000000                     2.096400e+04  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "## Zip -- Cleaning MN #\n",
    "#######################\n",
    "zip_df.shape\n",
    "#Understand range of outputs\n",
    "zip_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionName                                    0\n",
       "InventorySeasonallyAdjusted_AllHomes    3332781\n",
       "InventoryRaw_AllHomes                   3332781\n",
       "MedianListingPricePerSqft_1Bedroom      4375691\n",
       "MedianListingPricePerSqft_2Bedroom      4297331\n",
       "                                         ...   \n",
       "ZRI_AllHomes                            3046523\n",
       "ZRI_AllHomesPlusMultifamily             3044532\n",
       "ZriPerSqft_AllHomes                     3129916\n",
       "Zri_MultiFamilyResidenceRental          3660343\n",
       "Zri_SingleFamilyResidenceRental         3049564\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Understand the number of nulls\n",
    "zip_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish two new columns in order to test logic of replacement / consolidation\n",
    "zip_df['NumberOfBedrooms'] = 0\n",
    "zip_df['DwellingType'] = 0\n",
    "zip_df['MedianListingPricePerSqft'] = 0\n",
    "zip_df['MedianListingPrice'] = 0\n",
    "zip_df['MedianRentalPrice'] = 0\n",
    "zip_df['MedianRentalPricePerSqft'] = 0\n",
    "zip_df['MedianListPPS_D'] = 0\n",
    "zip_df['MedianList_D'] = 0\n",
    "zip_df['MedianRentalPPS_D'] = 0\n",
    "zip_df['MedianRental_D'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace null with 0\n",
    "zip_df['MedianListingPricePerSqft_1Bedroom'] = zip_df['MedianListingPricePerSqft_1Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_2Bedroom'] = zip_df['MedianListingPricePerSqft_2Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_3Bedroom'] = zip_df['MedianListingPricePerSqft_3Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_4Bedroom'] = zip_df['MedianListingPricePerSqft_4Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_5BedroomOrMore'] = zip_df['MedianListingPricePerSqft_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_1Bedroom'] = zip_df['MedianListingPrice_1Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_2Bedroom'] = zip_df['MedianListingPrice_2Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_3Bedroom'] = zip_df['MedianListingPrice_3Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_4Bedroom'] = zip_df['MedianListingPrice_4Bedroom'].fillna(0)\n",
    "zip_df['MedianListingPrice_5BedroomOrMore'] = zip_df['MedianListingPrice_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPricePerSqft_1Bedroom'] = zip_df['MedianRentalPricePerSqft_1Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_2Bedroom'] = zip_df['MedianRentalPricePerSqft_2Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_3Bedroom'] = zip_df['MedianRentalPricePerSqft_3Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_4Bedroom'] = zip_df['MedianRentalPricePerSqft_4Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_5BedroomOrMore'] = zip_df['MedianRentalPricePerSqft_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPrice_1Bedroom'] = zip_df['MedianRentalPrice_1Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_2Bedroom'] = zip_df['MedianRentalPrice_2Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_3Bedroom'] = zip_df['MedianRentalPrice_3Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_4Bedroom'] = zip_df['MedianRentalPrice_4Bedroom'].fillna(0)\n",
    "zip_df['MedianRentalPrice_5BedroomOrMore'] = zip_df['MedianRentalPrice_5BedroomOrMore'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_AllHomes'] = zip_df['MedianListingPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPrice_CondoCoop'] = zip_df['MedianListingPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPrice_DuplexTriplex'] = zip_df['MedianListingPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPrice_SingleFamilyResidence'] = zip_df['MedianListingPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPrice_AllHomes'] = zip_df['MedianListingPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPrice_CondoCoop'] = zip_df['MedianListingPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPrice_DuplexTriplex'] = zip_df['MedianListingPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPrice_SingleFamilyResidence'] = zip_df['MedianListingPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianListingPricePerSqft_AllHomes'] = zip_df['MedianListingPricePerSqft_AllHomes'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_CondoCoop'] = zip_df['MedianListingPricePerSqft_CondoCoop'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_DuplexTriplex'] = zip_df['MedianListingPricePerSqft_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianListingPricePerSqft_SingleFamilyResidence'] = zip_df['MedianListingPricePerSqft_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPrice_AllHomes'] = zip_df['MedianRentalPrice_AllHomes'].fillna(0)\n",
    "zip_df['MedianRentalPrice_CondoCoop'] = zip_df['MedianRentalPrice_CondoCoop'].fillna(0)\n",
    "zip_df['MedianRentalPrice_DuplexTriplex'] = zip_df['MedianRentalPrice_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianRentalPrice_SingleFamilyResidence'] = zip_df['MedianRentalPrice_SingleFamilyResidence'].fillna(0)\n",
    "##\n",
    "zip_df['MedianRentalPricePerSqft_AllHomes'] = zip_df['MedianRentalPricePerSqft_AllHomes'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_CondoCoop'] = zip_df['MedianRentalPricePerSqft_CondoCoop'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_DuplexTriplex'] = zip_df['MedianRentalPricePerSqft_DuplexTriplex'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'] = zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'] = zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_Studio'] = zip_df['MedianRentalPricePerSqft_Studio'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_AllHomes'] = zip_df['MedianPctOfPriceReduction_AllHomes'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_CondoCoop'] = zip_df['MedianPctOfPriceReduction_CondoCoop'].fillna(0)\n",
    "zip_df['MedianPctOfPriceReduction_SingleFamilyResidence'] = zip_df['MedianPctOfPriceReduction_SingleFamilyResidence'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_AllHomes'] = zip_df['MedianPriceCutDollar_AllHomes'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_CondoCoop'] = zip_df['MedianPriceCutDollar_CondoCoop'].fillna(0)\n",
    "zip_df['MedianPriceCutDollar_SingleFamilyResidence'] = zip_df['MedianPriceCutDollar_SingleFamilyResidence'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'] = zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'].fillna(0)\n",
    "zip_df['MedianRentalPricePerSqft_Studio'] = zip_df['MedianRentalPricePerSqft_Studio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized set in order to iterate through and assign a value to the new column created\n",
    "## Many prior attempts utilized a more if then style structure but inevitably took a considerably long time\n",
    "## and replaced when the value was 0  thus overwriting the prior data at every run\n",
    "##WC: https://guillim.github.io/pandas/2018/10/22/Pandas-if-else-on-columns.html \n",
    "\n",
    "condlist = [\n",
    "    (zip_df['MedianListingPricePerSqft_1Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_2Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_3Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_4Bedroom'] != 0)\n",
    "    ,(zip_df['MedianListingPricePerSqft_5BedroomOrMore'] != 0)\n",
    "]\n",
    "\n",
    "condlist2 = [(zip_df['MedianRentalPricePerSqft_AllHomes'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_CondoCoop'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_DuplexTriplex'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_MultiFamilyResidence5PlusUnits'] != 0)\n",
    "    ,(zip_df['MedianRentalPricePerSqft_Studio'] != 0)\n",
    "]\n",
    "      \n",
    "#Establish if the criteria is met - what is the result\n",
    "choicelist = [1,2,3,4,5]\n",
    "choicelist2 = ['All','Condo','Duplex+','Single','Multi5+','Studio']\n",
    "#Overwrite the number of bedroom columns with the given logic output \n",
    "zip_df['NumberOfBedrooms'] = np.select(condlist,choicelist)\n",
    "zip_df['DwellingType'] = np.select(condlist2,choicelist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumberOfBedrooms\n",
       "0    3951999\n",
       "1       8194\n",
       "2      80569\n",
       "3     310476\n",
       "4      30627\n",
       "5       2020\n",
       "Name: NumberOfBedrooms, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count per of decided bedrooms\n",
    "zip_df['NumberOfBedrooms'].groupby(zip_df['NumberOfBedrooms']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DwellingType\n",
       "0          4234042\n",
       "All         120843\n",
       "Condo          677\n",
       "Duplex+       1231\n",
       "Multi5+      25631\n",
       "Single         924\n",
       "Studio         537\n",
       "Name: DwellingType, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count per of decided dwelling types\n",
    "zip_df['DwellingType'].groupby(zip_df['DwellingType']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Further Cleanup of like variables\n",
    "\n",
    "## Optimized set in order to iterate through and assign a value to the new column created\n",
    "## Many prior attempts utilized a more if then style structure but inevitably took a considerably long time\n",
    "## and replaced when the value was 0  thus overwriting the prior data at every run\n",
    "##WC: https://guillim.github.io/pandas/2018/10/22/Pandas-if-else-on-columns.html \n",
    "\n",
    "#condlist2 = [\n",
    "#    (zip_df['MedianListingPrice_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_1Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_2Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_3Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_4Bedroom'] != 0)\n",
    "#    ,(zip_df['MedianListingPrice_5BedroomOrMore'] != 0)\n",
    "#    ,(zip_df['MedianRentalPrice_5BedroomOrMore'] != 0)\n",
    "#    ,(zip_df['MedianRentalPricePerSqft_5BedroomOrMore'] != 0)\n",
    "#]\n",
    "#Establish if the criteria is met - what is the result\n",
    "#choicelist2 = [1,1,1,2,2,2,3,3,3,4,4,4,5,5,5]\n",
    "#Overwrite the number of bedroom columns with the given logic output \n",
    "#zip_df['NumberOfBedrooms'] = np.select(condlist2,choicelist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combine the bedroom columns into the median listing price per sqft column to reduce column space\n",
    "\n",
    "zip_df['MedianListingPricePerSqft'] = (zip_df['MedianListingPricePerSqft_1Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_2Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_3Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_4Bedroom']\n",
    "          + zip_df['MedianListingPricePerSqft_5BedroomOrMore'])\n",
    "zip_df['MedianListingPrice'] = (zip_df['MedianListingPrice_1Bedroom']\n",
    "          + zip_df['MedianListingPrice_2Bedroom']\n",
    "          + zip_df['MedianListingPrice_3Bedroom']\n",
    "          + zip_df['MedianListingPrice_4Bedroom']\n",
    "          + zip_df['MedianListingPrice_5BedroomOrMore'])\n",
    "zip_df['MedianRentalPricePerSqft'] = (zip_df['MedianRentalPricePerSqft_1Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_2Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_3Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_4Bedroom']\n",
    "          + zip_df['MedianRentalPricePerSqft_5BedroomOrMore'])\n",
    "zip_df['MedianRentalPrice'] = (zip_df['MedianRentalPrice_1Bedroom']\n",
    "          + zip_df['MedianRentalPrice_2Bedroom']\n",
    "          + zip_df['MedianRentalPrice_3Bedroom']\n",
    "          + zip_df['MedianRentalPrice_4Bedroom']\n",
    "          + zip_df['MedianRentalPrice_5BedroomOrMore'])\n",
    "zip_df['MedianListPPS_D'] = (zip_df['MedianListingPricePerSqft_AllHomes']\n",
    "          + zip_df['MedianListingPricePerSqft_CondoCoop']\n",
    "          + zip_df['MedianListingPricePerSqft_DuplexTriplex']\n",
    "          + zip_df['MedianListingPricePerSqft_SingleFamilyResidence'])\n",
    "zip_df['MedianList_D'] = (zip_df['MedianListingPrice_AllHomes']\n",
    "          + zip_df['MedianListingPrice_CondoCoop']\n",
    "          + zip_df['MedianListingPrice_DuplexTriplex']\n",
    "          + zip_df['MedianListingPrice_SingleFamilyResidence'])\n",
    "zip_df['MedianRentalPPS_D'] = (zip_df['MedianRentalPricePerSqft_AllHomes']\n",
    "          + zip_df['MedianRentalPricePerSqft_CondoCoop']\n",
    "          + zip_df['MedianRentalPricePerSqft_DuplexTriplex']\n",
    "          + zip_df['MedianRentalPricePerSqft_SingleFamilyResidence'])\n",
    "zip_df['MedianRental_D'] = (zip_df['MedianRentalPrice_AllHomes']\n",
    "          + zip_df['MedianRentalPrice_CondoCoop']\n",
    "          + zip_df['MedianRentalPrice_DuplexTriplex']\n",
    "          + zip_df['MedianRentalPrice_SingleFamilyResidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop unneeded columns\n",
    "zip_df = zip_df[[\n",
    "         'RegionName'\n",
    "        , 'NumberOfBedrooms'\n",
    "        , 'DwellingType'\n",
    "        , 'MedianListingPricePerSqft'\n",
    "        , 'MedianListingPrice'\n",
    "        #, 'MedianRentalPrice'\n",
    "        #, 'MedianRentalPricePerSqft'\n",
    "        #, 'MedianListPPS_D'\n",
    "        #, 'MedianList_D'\n",
    "        #, 'MedianRentalPPS_D'\n",
    "        #, 'MedianRental_D'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Factorize the dwelling\n",
    "## Ensure weight is given to the size\n",
    "Dwelling_Type = {'All':6,\n",
    "             'Multi5':5,\n",
    "             'Duplex+':4,\n",
    "             'Condo':3,\n",
    "             'Single':2,\n",
    "             'Studio':1}\n",
    "zip_df['DwellingType'] = zip_df['DwellingType'].map(Dwelling_Type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create column for input / remove all 0s\n",
    "zip_df['Test'] = (zip_df['NumberOfBedrooms']\n",
    "+ zip_df['DwellingType']\n",
    "+ zip_df['MedianListingPricePerSqft']\n",
    "+ zip_df['MedianListingPrice']\n",
    "#+ zip_df['MedianRentalPrice']\n",
    "#+ zip_df['MedianRentalPricePerSqft']\n",
    "#+ zip_df['MedianListPPS_D']\n",
    "#+ zip_df['MedianList_D']\n",
    "#+ zip_df['MedianRentalPPS_D']\n",
    "#+ zip_df['MedianRental_D']\n",
    "                 )\n",
    "\n",
    "zip_df['Test'] = zip_df['Test'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish variable for sqft\n",
    "zip_df['sqft'] = zip_df['MedianListingPrice'] / zip_df['MedianListingPricePerSqft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-define the dataset and remove the just built test column\n",
    "zip_df = zip_df[(zip_df['Test'] !=0)]\n",
    "zip_df.drop(['Test','MedianListingPricePerSqft'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-define the dataset and remove missing median listing prices\n",
    "zip_df = zip_df[(zip_df['MedianListingPrice'] !=0)]\n",
    "#zip_multi = zip_multi[(zip_multi['MedianListingPrice'] !=0)]\n",
    "zip_df = zip_df[zip_df.MedianListingPrice.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75945, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish date range to 2017 for normalization\n",
    "#zip_df = zip_df.loc['2017-01-01':'2017-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilize groupby to aggregate values by region name, then dwelling type, and number of bedrooms\n",
    "## This will allow us to quickly index our data\n",
    "## By not adding the aggretation function at this stage, it will showcase if certain regions are more prevalent\n",
    "## before blending\n",
    "zip_multi = zip_df.groupby(['RegionName','DwellingType','NumberOfBedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>NumberOfBedrooms</th>\n",
       "      <th>DwellingType</th>\n",
       "      <th>MedianListingPrice</th>\n",
       "      <th>sqft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>23462</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436950.0</td>\n",
       "      <td>1111.457098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>33139</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>812000.0</td>\n",
       "      <td>990.545526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>33140</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>738000.0</td>\n",
       "      <td>1044.158347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>92270</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1820000.0</td>\n",
       "      <td>2545.619819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>23320</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1151913.0</td>\n",
       "      <td>2038.600366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>98682</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>724300.0</td>\n",
       "      <td>2122.180846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>99507</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>849500.0</td>\n",
       "      <td>1587.799198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>99508</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>742900.0</td>\n",
       "      <td>1535.502367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>99515</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>772200.0</td>\n",
       "      <td>2057.660929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>99654</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1124999.5</td>\n",
       "      <td>2506.540336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11432 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RegionName  NumberOfBedrooms  DwellingType  MedianListingPrice         sqft\n",
       "Date                                                                                   \n",
       "2010-02-28       23462                 2           6.0            436950.0  1111.457098\n",
       "2010-02-28       33139                 1           6.0            812000.0   990.545526\n",
       "2010-02-28       33140                 1           6.0            738000.0  1044.158347\n",
       "2010-02-28       92270                 2           3.0           1820000.0  2545.619819\n",
       "2010-03-31       23320                 2           6.0           1151913.0  2038.600366\n",
       "...                ...               ...           ...                 ...          ...\n",
       "2017-05-31       98682                 3           6.0            724300.0  2122.180846\n",
       "2017-05-31       99507                 2           6.0            849500.0  1587.799198\n",
       "2017-05-31       99508                 2           6.0            742900.0  1535.502367\n",
       "2017-05-31       99515                 3           6.0            772200.0  2057.660929\n",
       "2017-05-31       99654                 3           6.0           1124999.5  2506.540336\n",
       "\n",
       "[11432 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-f008ab00493b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#T.groupby(T).count()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    704\u001b[0m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "##\n",
    "T = zip_multi['RegionName']\n",
    "type(T)\n",
    "T.value_counts()\n",
    "#T.groupby(T).count()\n",
    "T.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilize to re-write base and blend into one record per zip code / dwelling / median listing\n",
    "zip_multi = zip_df.groupby(['RegionName','DwellingType','NumberOfBedrooms']).agg({'MedianListingPrice':['mean']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MedianListingPrice, mean)\n",
       "1.585665e+07                  1\n",
       "3.651085e+05                  1\n",
       "3.735341e+05                  1\n",
       "3.728688e+05                  1\n",
       "3.726339e+05                  1\n",
       "                             ..\n",
       "7.606916e+05                  1\n",
       "7.606582e+05                  1\n",
       "7.603677e+05                  1\n",
       "7.599045e+05                  1\n",
       "3.456042e+04                  1\n",
       "Length: 2360, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_multi.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipt_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename column to fall in line with other code for joining\n",
    "zip_df.rename(columns = {'RegionName': 'ZIP'}, inplace=True)\n",
    "zip_multi.rename(columns = {'RegionName': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Hospital Quality Care -- Cleaning SL #\n",
    "#########################################\n",
    "hospital_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_df = hospital_df.isnull().sum(axis = 0).sort_values().to_frame('missing_value')\n",
    "null_df[null_df['missing_value'] > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop provider id, hospital name, address, phone number since they are all irrelevant \n",
    "# also drop all footnote since they are all incorporate in the other columns.\n",
    "drop_these = ['Provider ID', 'Hospital Name', 'Phone Number']\n",
    "drop_these.extend([col for col in hospital_df if 'footnote' in col])\n",
    "hospital_df = hospital_df.drop(columns = drop_these)\n",
    "\n",
    "# hospital_df.loc[:,hospital_df.columns.str.endswith('footnote')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = hospital_df.isnull().sum(axis = 0).sort_values().to_frame('missing_value')\n",
    "null_df[null_df['missing_value'] > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hospital_df['Meets criteria for meaningful use of EHRs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Meets criteria for meaningful use of EHRs'] = hospital_df['Meets criteria for meaningful use of EHRs'].fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['County Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Hospital Ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Hospital Ownership'] = hospital_df['Hospital Ownership'].replace({\n",
    "                    'Voluntary non-profit - Private': 'non-profit', \n",
    "                    'Proprietary':'for-profit', \n",
    "                    'Government - Hospital District or Authority': 'government',\n",
    "                    'Voluntary non-profit - Other':'non-profit',\n",
    "                    'Government - Local':'government',\n",
    "                    'Voluntary non-profit - Church':'non-profit',\n",
    "                    'Physician':'for-profit',\n",
    "                    'Government - State':'government',\n",
    "                    'Tribal ':'government',\n",
    "                    'Government - Federal':'government',\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hospital_df['Hospital Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four level in the following 7 aspect: \n",
    "Mortality national comparison; \n",
    "Safety of care national comparison;\n",
    "Safety of care national comparison;\n",
    "Readmission national comparison\tPatient experience national comparison\tEffectiveness of care national comparison\tTimeliness of care national comparison\tEfficient use of medical imaging national comparison\n",
    "-1 Below the national average\n",
    "0Same as the national average                    \n",
    "1Above the national average       \n",
    "Not Available   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are four level in the following 7 aspect\n",
    "#Same as the national average    \n",
    "#Not Available                   \n",
    "#Above the national average       \n",
    "#Below the national average\n",
    "hospital_df['Mortality national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Safety of care national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hospital_df['Readmission national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df['Safety of care national comparison'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Consolidate dataframes for ease of use\n",
    "#pd.concat()\n",
    "PS_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Column\n",
    "food_df.rename(columns = {'Zipcode': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join food to PS data (want to make sure keep as much data as possible)\n",
    "PS_food_df = PS_df.merge(food_df, on=\"ZIP\", how=\"left\") \n",
    "PS_food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_food_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename SBUX and TGT columns\n",
    "SBUX_df.rename(columns = {'Postcode': 'ZIP'}, inplace=True)\n",
    "TGT_df.rename(columns = {'PostalCode': 'ZIP'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join TGT to SBUX\n",
    "SBUX_TGT_df = SBUX_df.merge(TGT_df, on=\"ZIP\", how=\"left\")\n",
    "SBUX_TGT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBUX_TGT_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = PS_food_df.merge(SBUX_TGT_df, on=\"ZIP\", how=\"left\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NA's with 0 for Starbucks and Target because those zipcodes don't have locations. \n",
    "features_df[['Starbucks_count', 'Target_count']] = features_df[['Starbucks_count', 'Target_count']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the data\n",
    "features_df.to_csv('CleanHouse.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the data\n",
    "df = pd.read_csv('CleanHouse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visually represent collinearity\n",
    "#Visually represent collinearity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(features_df.corr(),annot=True,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Reduction & Quick Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before impute in featuer engineering, attempt KDE\n",
    "How data is distributed at high level and potential data generation for specific features. Test different features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot one-dimension data ()\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Gaussian KDE with Seaborn bandwidth\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=bw)\n",
    "\n",
    "# Grab the data, and compute the support (sampling points)\n",
    "x = dataset['SepalLengthCm']\n",
    "support = np.linspace(3, 9, len(x))\n",
    "\n",
    "# Create the KDE, and return the support values.\n",
    "kde.fit(x[:, np.newaxis])\n",
    "y = kde.score_samples(support[:, np.newaxis])\n",
    "\n",
    "# Plot the results including underlying histogram\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(x, bins=10, alpha=0.5, color=sns.xkcd_rgb[\"denim blue\"], normed=True)\n",
    "ax.plot(support, np.exp(y))\n",
    "plt.xlabel('Sepal Length', fontsize=14)\n",
    "plt.title('Kernel Density Plot', fontsize=14)\n",
    "\n",
    "sns.despine(offset=5, trim=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If want to test for different bandwidth selection\n",
    "# Compare the impact of bandwidth selection on a KDE\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# Make plots\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(x, bins=10, alpha=0.5, color=sns.xkcd_rgb[\"denim blue\"], normed=True, label='')\n",
    "\n",
    "# Gaussian KDE with varying bandwidths\n",
    "for bw in np.linspace(0.1, 0.9, 4):\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bw)\n",
    "    kde.fit(x[:, np.newaxis])\n",
    "    y = kde.score_samples(support[:, np.newaxis])\n",
    "    ax.plot(support, np.exp(y), label='bw = {0:3.1f}'.format(bw))\n",
    "\n",
    "# Decorate plot\n",
    "plt.xlabel('Sepal Length', fontsize=14)\n",
    "plt.title('Kernel Density Plot', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine(offset=5, trim=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In event that want to use this data generation, can sample from scikit learn KDE model\n",
    "# We can now sample from the scikit learn KDE model\n",
    "for val in kde.sample(n_samples=15):\n",
    "    print('{0:4.1f}, '.format(val[0]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = train_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca(df, n_components):\n",
    "    pca = PCA(n_components)  \n",
    "    pca = pca.fit(df)  #fit the PCA model to the df (which will be the original, non-reduced df when used below)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep only 10 components\n",
    "n_components = 10\n",
    "pca = fit_pca(train_standardized, n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaled_variance(pca):\n",
    "    #same as above, create a subplot, decorate the plot, and show the percentage of variance\n",
    "    fig, ax = plt.subplots(figsize=(10, 6)) \n",
    "    ax.set_xlabel('Dimension #')\n",
    "    ax.set_ylabel('Explained Variance Ratio')\n",
    "    ax.set_title('Fraction of Explained Variance')\n",
    "    ax.plot(pca.explained_variance_ratio_)   \n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_scaled_variance(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Just compare loan_amount and loan_grade\n",
    "data_loangrade_cluster = data[['loan_amount', 'loan_grade']]\n",
    "#turn to matrix\n",
    "data_loangrade_cluster = data_loangrade_cluster.as_matrix().astype(\"float32\", copy = False)\n",
    "\n",
    "#Create a standardizer\n",
    "data_standardized = StandardScaler().fit_transform(data_loangrade_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply k-nearest to determine best suitable esp neighborhood for DBSCAN (the knee in the plot)\n",
    "#min.sample = # of dimensions + 1 --> 2+1 = 3. Use 3 to start with. \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=2).fit(data_standardized)\n",
    "distances, indices = nbrs.kneighbors(data_standardized)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#fit data to DBSCAN function. In this case use radius (aka epsilon) of 0.01 per k-nearest and min_samples of 5\n",
    "dbsc = DBSCAN(eps = 0.01, min_samples = 5).fit(data_standardized)\n",
    "#Get the cluster labels\n",
    "labels = dbsc.labels_\n",
    "#Identify the core and border points\n",
    "core_samples = np.zeros_like(labels, dtype = bool)\n",
    "core_samples[dbsc.core_sample_indices_] = True\n",
    "\n",
    "#Pair labels with colors\n",
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0,1, len(unique_labels)))\n",
    "\n",
    "#Plot the data \n",
    "for (label, color) in zip(unique_labels, colors):\n",
    "    class_member_mask = (labels == label)\n",
    "    xy = data_standardized[class_member_mask & core_samples]  \n",
    "    plt.plot(xy[:,0],xy[:,1], 'o', markerfacecolor = color, markersize = 10)\n",
    "    \n",
    "    xy2 = data_standardized[class_member_mask & ~core_samples]\n",
    "    plt.plot(xy2[:,0],xy2[:,1], 'o', markerfacecolor = color, markersize = 5)\n",
    "    \n",
    "#Decorate the plot\n",
    "plt.title(\"DBSCAN on Standardized Loan data\")\n",
    "plt.xlabel(\"Feature1\")\n",
    "plt.ylabel(\"Feature2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "https://pypi.org/project/autoimpute/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(test as much algorithm as possible, possible models include Random Forest, Gradient Boosting, Ada-Boosting, Voting Classifier...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate function\n",
    "regressor = LinearRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model with training data\n",
    "regressor.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute y predictor: predict the target (Y) on the testing dataset\n",
    "pred_y = regressor.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desired Error\n",
    "## Evaluate the RMSE on the testing dataset to get the desired error\n",
    "# Compute mse\n",
    "mse = MSE(test_y, pred_y)\n",
    "\n",
    "# Compute rmse & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "rmse = (mse**(1/2))*100\n",
    "\n",
    "# Print rmse\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression: Training Error\n",
    "#predict the target on the train dataset\n",
    "y_pred_train = regressor.predict(train_X)\n",
    "\n",
    "##Evaluate RMSE on the training dataset to get the training error\n",
    "#Compute mse\n",
    "mse = MSE(train_y, y_pred_train)\n",
    "\n",
    "#Compute rmse & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "RMSE_train = (mse**(1/2))*100\n",
    "\n",
    "#Print RMSE train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression: Cross Validation\n",
    "## Cross Validate \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(regressor, train_X, train_y, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "RMSE_CV = ((MSE_CV_scores.mean())**(1/2))*100\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeRegressor from sklearn.tree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply cv.train_test (produce new split here)\n",
    "(X_train, X_test, y_train, y_test) = cv.train_test_split(X, y, test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.05, 0.10, 0.13, 0.15, 0.20, 0.26, 0.5]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, cv = 10, random_state=3, n_jobs = -1)\n",
    "#dt_random = RandomizedSearchCV(estimator = dt, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=3, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "dt_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See what best parameters from fitting the random search: \n",
    "dt_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_leaf=0.1,\n",
    "                           random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree: Desired error\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "rmse_dt = (mse_dt**(1/2))*100\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: Training Error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  n_jobs=-1) \n",
    "\n",
    "# Compute the 10-folds CV RMSE & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "RMSE_CV = ((MSE_CV_scores.mean())**(1/2)) * 100\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: Training Error\n",
    "# Fit dt to the training set\n",
    "#dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "RMSE_train = ((MSE(y_train, y_pred_train))**(1/2))*100\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.05, 0.10, 0.13, 0.15, 0.20, 0.26, 0.5]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, cv = 10, random_state=3, n_jobs = -1)\n",
    "#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=3, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See what best parameters from fitting the random search: \n",
    "dt_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a random forests regressor 'rf' 600 estimators\n",
    "rf = RandomForestRegressor(n_estimators=600,\n",
    "min_samples_leaf=0.01,\n",
    "random_state=SEED)\n",
    "\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest: Desired Error\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "rmse_test = (MSE(y_test, y_pred)**(1/2))*100\n",
    "\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest: Train Error\n",
    "# Predict the train features\n",
    "y_pred_train=rf.predict(X_train)\n",
    "\n",
    "# Evaluate the train set RMSE & multiply by 100 because I turned % values to decimal which will affect the MSE/RMSE score\n",
    "rmse_train = (MSE(y_train, y_pred_train)**(1/2))*100\n",
    "\n",
    "# Print the train set RMSE\n",
    "print('Train set RMSE of rf: {:.2f}'.format(rmse_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't need to do cross-validation when using random forest because mutliple bagging in process of training random forest \n",
    "#prevents over-fitting.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_,\n",
    "index = X.columns)\n",
    "\n",
    "# Sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "\n",
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save model to pickle import\n",
    "import pickle\n",
    "\n",
    "#Save\n",
    "model_rf_file = open(\"FinalProjectModel.pkl\", \"wb\")\n",
    "pickle.dump(rf, model_rf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading\n",
    "model_rf_file = open('GarciaC_assignment3.pkl', 'rb')\n",
    "rf_pi2 = pickle.load(model_rf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the model: use loaded picked model to make predictions\n",
    "#this is the code used to apply the model used to make predictions.  \n",
    "y_pred_train = rf_pi2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split test data \n",
    "X_Htest, y_Htest  = test_holdout.drop(['loan_interest_rate'], axis =1), test_holdout['loan_interest_rate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict \n",
    "y_pred_rf = rf_pi2.predict(X_Htest)\n",
    "print(y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(data = y_pred_rf, columns=['loan_interest_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['loan_interest_rate'] = final_data['loan_interest_rate'].mul(100).round(2).astype(str)+'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Results to csv\n",
    "final_data.to_csv(\"FinalProjectResults.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
